Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/12/18 18:27:49 INFO SparkContext: Running Spark version 2.2.2-SNAPSHOT
17/12/18 18:27:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/18 18:27:49 INFO SparkContext: Submitted application: ModelSelectionViaTrainValidationSplitExample
17/12/18 18:27:49 INFO SecurityManager: Changing view acls to: kderment
17/12/18 18:27:49 INFO SecurityManager: Changing modify acls to: kderment
17/12/18 18:27:49 INFO SecurityManager: Changing view acls groups to: 
17/12/18 18:27:49 INFO SecurityManager: Changing modify acls groups to: 
17/12/18 18:27:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kderment); groups with view permissions: Set(); users  with modify permissions: Set(kderment); groups with modify permissions: Set()
17/12/18 18:27:49 INFO Utils: Successfully started service 'sparkDriver' on port 46353.
17/12/18 18:27:49 INFO SparkEnv: Registering MapOutputTracker
17/12/18 18:27:49 INFO SparkEnv: Registering BlockManagerMaster
17/12/18 18:27:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/18 18:27:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/18 18:27:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6b823746-98a9-4d65-8689-d537bf2812f1
17/12/18 18:27:49 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/18 18:27:49 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/18 18:27:49 INFO log: Logging initialized @1274ms
17/12/18 18:27:49 INFO Server: jetty-9.3.11.v20160721
17/12/18 18:27:49 INFO Server: Started @1332ms
17/12/18 18:27:50 INFO AbstractConnector: Started ServerConnector@58f0ef64{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/12/18 18:27:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@214894fc{/jobs,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2fb68ec6{/jobs/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3add81c4{/jobs/job,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@159e366{/jobs/job/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24528a25{/stages,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59221b97{/stages/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5a772895{/stages/stage,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5d332969{/stages/stage/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2e27d72f{/stages/pool,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4837595f{/stages/pool/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b718392{/storage,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f2d2181{/storage/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ee55e70{/storage/rdd,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7668d560{/storage/rdd/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@126be319{/environment,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5c371e13{/environment/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e34c607{/executors,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36b6964d{/executors/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@9257031{/executors/threadDump,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7726e185{/executors/threadDump/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@282308c3{/static,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@38d5b107{/api,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30457e14{/jobs/job/kill,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@632aa1a3{/stages/stage/kill,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://138.96.200.169:4040
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/htrace-core-3.0.4.jar at spark://138.96.200.169:46353/jars/htrace-core-3.0.4.jar with timestamp 1513618070067
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javax.annotation-api-1.2.jar at spark://138.96.200.169:46353/jars/javax.annotation-api-1.2.jar with timestamp 1513618070067
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-streaming_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-streaming_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070067
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/osgi-resource-locator-1.0.1.jar at spark://138.96.200.169:46353/jars/osgi-resource-locator-1.0.1.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/avro-ipc-1.7.7.jar at spark://138.96.200.169:46353/jars/avro-ipc-1.7.7.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scala-library-2.11.8.jar at spark://138.96.200.169:46353/jars/scala-library-2.11.8.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-unsafe_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-unsafe_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-configuration-1.6.jar at spark://138.96.200.169:46353/jars/commons-configuration-1.6.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/ST4-4.0.4.jar at spark://138.96.200.169:46353/jars/ST4-4.0.4.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/xercesImpl-2.9.1.jar at spark://138.96.200.169:46353/jars/xercesImpl-2.9.1.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jcl-over-slf4j-1.7.16.jar at spark://138.96.200.169:46353/jars/jcl-over-slf4j-1.7.16.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jets3t-0.9.3.jar at spark://138.96.200.169:46353/jars/jets3t-0.9.3.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/breeze-macros_2.11-0.13.2.jar at spark://138.96.200.169:46353/jars/breeze-macros_2.11-0.13.2.jar with timestamp 1513618070068
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javax.inject-2.4.0-b34.jar at spark://138.96.200.169:46353/jars/javax.inject-2.4.0-b34.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/compress-lzf-1.0.3.jar at spark://138.96.200.169:46353/jars/compress-lzf-1.0.3.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/validation-api-1.1.0.Final.jar at spark://138.96.200.169:46353/jars/validation-api-1.1.0.Final.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-dbcp-1.4.jar at spark://138.96.200.169:46353/jars/commons-dbcp-1.4.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/JavaEWAH-0.3.2.jar at spark://138.96.200.169:46353/jars/JavaEWAH-0.3.2.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-mllib_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-mllib_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-servlet-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-servlet-9.3.11.v20160721.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scopt_2.11-3.3.0.jar at spark://138.96.200.169:46353/jars/scopt_2.11-3.3.0.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/chill_2.11-0.8.0.jar at spark://138.96.200.169:46353/jars/chill_2.11-0.8.0.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-container-servlet-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-container-servlet-2.22.2.jar with timestamp 1513618070069
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/servlet-api-2.5-20110124.jar at spark://138.96.200.169:46353/jars/servlet-api-2.5-20110124.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-client-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-client-9.3.11.v20160721.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-launcher_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-launcher_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/calcite-linq4j-1.2.0-incubating.jar at spark://138.96.200.169:46353/jars/calcite-linq4j-1.2.0-incubating.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-streaming-flume_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-streaming-flume_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-beanutils-core-1.8.0.jar at spark://138.96.200.169:46353/jars/commons-beanutils-core-1.8.0.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/java-xmlbuilder-1.0.jar at spark://138.96.200.169:46353/jars/java-xmlbuilder-1.0.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-hdfs-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-hdfs-2.6.5.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/stax-api-1.0.1.jar at spark://138.96.200.169:46353/jars/stax-api-1.0.1.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jtransforms-2.4.0.jar at spark://138.96.200.169:46353/jars/jtransforms-2.4.0.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-common-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-common-2.6.5.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/flume-ng-sdk-1.6.0.jar at spark://138.96.200.169:46353/jars/flume-ng-sdk-1.6.0.jar with timestamp 1513618070070
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/pyrolite-4.13.jar at spark://138.96.200.169:46353/jars/pyrolite-4.13.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javassist-3.18.1-GA.jar at spark://138.96.200.169:46353/jars/javassist-3.18.1-GA.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jettison-1.1.jar at spark://138.96.200.169:46353/jars/jettison-1.1.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-io-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-io-9.3.11.v20160721.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/paranamer-2.6.jar at spark://138.96.200.169:46353/jars/paranamer-2.6.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-module-paranamer-2.6.5.jar at spark://138.96.200.169:46353/jars/jackson-module-paranamer-2.6.5.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-graphx_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-graphx_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/ivy-2.4.0.jar at spark://138.96.200.169:46353/jars/ivy-2.4.0.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-crypto-1.0.0.jar at spark://138.96.200.169:46353/jars/commons-crypto-1.0.0.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-mapreduce-client-app-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-app-2.6.5.jar with timestamp 1513618070071
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/httpclient-4.5.2.jar at spark://138.96.200.169:46353/jars/httpclient-4.5.2.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/curator-recipes-2.6.0.jar at spark://138.96.200.169:46353/jars/curator-recipes-2.6.0.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/libfb303-0.9.3.jar at spark://138.96.200.169:46353/jars/libfb303-0.9.3.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-media-jaxb-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-media-jaxb-2.22.2.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/api-util-1.0.0-M20.jar at spark://138.96.200.169:46353/jars/api-util-1.0.0-M20.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/metrics-json-3.1.2.jar at spark://138.96.200.169:46353/jars/metrics-json-3.1.2.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hive-exec-1.2.1.spark2.jar at spark://138.96.200.169:46353/jars/hive-exec-1.2.1.spark2.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-util-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-util-9.3.11.v20160721.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spire_2.11-0.13.0.jar at spark://138.96.200.169:46353/jars/spire_2.11-0.13.0.jar with timestamp 1513618070072
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hk2-locator-2.4.0-b34.jar at spark://138.96.200.169:46353/jars/hk2-locator-2.4.0-b34.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-network-common_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-network-common_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/velocity-1.7.jar at spark://138.96.200.169:46353/jars/velocity-1.7.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/flume-ng-core-1.6.0.jar at spark://138.96.200.169:46353/jars/flume-ng-core-1.6.0.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-io-2.4.jar at spark://138.96.200.169:46353/jars/commons-io-2.4.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-container-servlet-core-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-container-servlet-core-2.22.2.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/apache-log4j-extras-1.2.17.jar at spark://138.96.200.169:46353/jars/apache-log4j-extras-1.2.17.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scala-reflect-2.11.8.jar at spark://138.96.200.169:46353/jars/scala-reflect-2.11.8.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javax.servlet-api-3.1.0.jar at spark://138.96.200.169:46353/jars/javax.servlet-api-3.1.0.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-encoding-1.8.2.jar at spark://138.96.200.169:46353/jars/parquet-encoding-1.8.2.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-yarn-server-common-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-yarn-server-common-2.6.5.jar with timestamp 1513618070073
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-xc-1.9.13.jar at spark://138.96.200.169:46353/jars/jackson-xc-1.9.13.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-pool-1.5.4.jar at spark://138.96.200.169:46353/jars/commons-pool-1.5.4.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-databind-2.6.5.jar at spark://138.96.200.169:46353/jars/jackson-databind-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/mina-core-2.0.4.jar at spark://138.96.200.169:46353/jars/mina-core-2.0.4.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-yarn-api-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-yarn-api-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/gson-2.2.4.jar at spark://138.96.200.169:46353/jars/gson-2.2.4.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/datanucleus-api-jdo-3.2.6.jar at spark://138.96.200.169:46353/jars/datanucleus-api-jdo-3.2.6.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-compiler-3.0.7.jar at spark://138.96.200.169:46353/jars/commons-compiler-3.0.7.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-yarn-common-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-yarn-common-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-core-asl-1.9.13.jar at spark://138.96.200.169:46353/jars/jackson-core-asl-1.9.13.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-collections-3.2.2.jar at spark://138.96.200.169:46353/jars/commons-collections-3.2.2.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-logging-1.2.jar at spark://138.96.200.169:46353/jars/commons-logging-1.2.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-common-1.8.2.jar at spark://138.96.200.169:46353/jars/parquet-common-1.8.2.jar with timestamp 1513618070074
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/unused-1.0.0.jar at spark://138.96.200.169:46353/jars/unused-1.0.0.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-digester-1.8.jar at spark://138.96.200.169:46353/jars/commons-digester-1.8.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/bcprov-jdk15on-1.51.jar at spark://138.96.200.169:46353/jars/bcprov-jdk15on-1.51.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/stream-2.7.0.jar at spark://138.96.200.169:46353/jars/stream-2.7.0.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jdo-api-3.0.1.jar at spark://138.96.200.169:46353/jars/jdo-api-3.0.1.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/guava-14.0.1.jar at spark://138.96.200.169:46353/jars/guava-14.0.1.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/avro-1.7.7.jar at spark://138.96.200.169:46353/jars/avro-1.7.7.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hk2-utils-2.4.0-b34.jar at spark://138.96.200.169:46353/jars/hk2-utils-2.4.0-b34.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-server-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-server-9.3.11.v20160721.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javax.inject-1.jar at spark://138.96.200.169:46353/jars/javax.inject-1.jar with timestamp 1513618070075
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-tags_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-tags_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/xmlenc-0.52.jar at spark://138.96.200.169:46353/jars/xmlenc-0.52.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-hadoop-bundle-1.6.0.jar at spark://138.96.200.169:46353/jars/parquet-hadoop-bundle-1.6.0.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/shapeless_2.11-2.3.2.jar at spark://138.96.200.169:46353/jars/shapeless_2.11-2.3.2.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-6.1.26.jar at spark://138.96.200.169:46353/jars/jetty-6.1.26.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-plus-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-plus-9.3.11.v20160721.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-lang3-3.5.jar at spark://138.96.200.169:46353/jars/commons-lang3-3.5.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/aopalliance-1.0.jar at spark://138.96.200.169:46353/jars/aopalliance-1.0.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jaxb-api-2.2.2.jar at spark://138.96.200.169:46353/jars/jaxb-api-2.2.2.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/curator-client-2.6.0.jar at spark://138.96.200.169:46353/jars/curator-client-2.6.0.jar with timestamp 1513618070076
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-core_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-core_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/metrics-core-3.1.2.jar at spark://138.96.200.169:46353/jars/metrics-core-3.1.2.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-cli-1.2.jar at spark://138.96.200.169:46353/jars/commons-cli-1.2.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spire-macros_2.11-0.13.0.jar at spark://138.96.200.169:46353/jars/spire-macros_2.11-0.13.0.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-catalyst_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-catalyst_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/metrics-jvm-3.1.2.jar at spark://138.96.200.169:46353/jars/metrics-jvm-3.1.2.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-column-1.8.2.jar at spark://138.96.200.169:46353/jars/parquet-column-1.8.2.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/janino-3.0.7.jar at spark://138.96.200.169:46353/jars/janino-3.0.7.jar with timestamp 1513618070077
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/guice-3.0.jar at spark://138.96.200.169:46353/jars/guice-3.0.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/avro-ipc-1.7.7-tests.jar at spark://138.96.200.169:46353/jars/avro-ipc-1.7.7-tests.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/mail-1.4.7.jar at spark://138.96.200.169:46353/jars/mail-1.4.7.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-client-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-client-2.22.2.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/pmml-schema-1.2.15.jar at spark://138.96.200.169:46353/jars/pmml-schema-1.2.15.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/py4j-0.10.4.jar at spark://138.96.200.169:46353/jars/py4j-0.10.4.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-auth-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-auth-2.6.5.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/bonecp-0.8.0.RELEASE.jar at spark://138.96.200.169:46353/jars/bonecp-0.8.0.RELEASE.jar with timestamp 1513618070078
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-client-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-client-2.6.5.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-mapper-asl-1.9.13.jar at spark://138.96.200.169:46353/jars/jackson-mapper-asl-1.9.13.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/antlr-runtime-3.4.jar at spark://138.96.200.169:46353/jars/antlr-runtime-3.4.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-guava-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-guava-2.22.2.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-annotations-2.6.5.jar at spark://138.96.200.169:46353/jars/jackson-annotations-2.6.5.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scalap-2.11.8.jar at spark://138.96.200.169:46353/jars/scalap-2.11.8.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-common-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-common-2.22.2.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/avro-mapred-1.7.7-hadoop2.jar at spark://138.96.200.169:46353/jars/avro-mapred-1.7.7-hadoop2.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/RoaringBitmap-0.5.11.jar at spark://138.96.200.169:46353/jars/RoaringBitmap-0.5.11.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/objenesis-2.1.jar at spark://138.96.200.169:46353/jars/objenesis-2.1.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/stax-api-1.0-2.jar at spark://138.96.200.169:46353/jars/stax-api-1.0-2.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-sketch_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-sketch_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/univocity-parsers-2.2.1.jar at spark://138.96.200.169:46353/jars/univocity-parsers-2.2.1.jar with timestamp 1513618070079
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/metrics-graphite-3.1.2.jar at spark://138.96.200.169:46353/jars/metrics-graphite-3.1.2.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/activation-1.1.1.jar at spark://138.96.200.169:46353/jars/activation-1.1.1.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/mx4j-3.0.2.jar at spark://138.96.200.169:46353/jars/mx4j-3.0.2.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/minlog-1.3.0.jar at spark://138.96.200.169:46353/jars/minlog-1.3.0.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-sql_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-sql_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/protobuf-java-2.5.0.jar at spark://138.96.200.169:46353/jars/protobuf-java-2.5.0.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/pmml-model-1.2.15.jar at spark://138.96.200.169:46353/jars/pmml-model-1.2.15.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/base64-2.3.8.jar at spark://138.96.200.169:46353/jars/base64-2.3.8.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/metrics-core-2.2.0.jar at spark://138.96.200.169:46353/jars/metrics-core-2.2.0.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/antlr-2.7.7.jar at spark://138.96.200.169:46353/jars/antlr-2.7.7.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/chill-java-0.8.0.jar at spark://138.96.200.169:46353/jars/chill-java-0.8.0.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/netty-all-4.0.43.Final.jar at spark://138.96.200.169:46353/jars/netty-all-4.0.43.Final.jar with timestamp 1513618070080
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/slf4j-api-1.7.21.jar at spark://138.96.200.169:46353/jars/slf4j-api-1.7.21.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/cglib-2.2.1-v20090111.jar at spark://138.96.200.169:46353/jars/cglib-2.2.1-v20090111.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-http-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-http-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/slf4j-log4j12-1.7.16.jar at spark://138.96.200.169:46353/jars/slf4j-log4j12-1.7.16.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-hadoop-1.8.2.jar at spark://138.96.200.169:46353/jars/parquet-hadoop-1.8.2.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hk2-api-2.4.0-b34.jar at spark://138.96.200.169:46353/jars/hk2-api-2.4.0-b34.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/core-1.1.2.jar at spark://138.96.200.169:46353/jars/core-1.1.2.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/api-asn1-api-1.0.0-M20.jar at spark://138.96.200.169:46353/jars/api-asn1-api-1.0.0-M20.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/json4s-jackson_2.11-3.2.11.jar at spark://138.96.200.169:46353/jars/json4s-jackson_2.11-3.2.11.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-net-3.1.jar at spark://138.96.200.169:46353/jars/commons-net-3.1.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/avro-compiler-1.7.3.jar at spark://138.96.200.169:46353/jars/avro-compiler-1.7.3.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-webapp-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-webapp-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-jndi-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-jndi-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-sql-kafka-0-10_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-sql-kafka-0-10_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070081
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jsr305-1.3.9.jar at spark://138.96.200.169:46353/jars/jsr305-1.3.9.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/flume-ng-auth-1.6.0.jar at spark://138.96.200.169:46353/jars/flume-ng-auth-1.6.0.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-lang-2.6.jar at spark://138.96.200.169:46353/jars/commons-lang-2.6.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-streaming-flume-sink_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-streaming-flume-sink_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/apacheds-i18n-2.0.0-M15.jar at spark://138.96.200.169:46353/jars/apacheds-i18n-2.0.0-M15.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-continuation-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-continuation-9.3.11.v20160721.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-mllib-local_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-mllib-local_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-format-2.3.1.jar at spark://138.96.200.169:46353/jars/parquet-format-2.3.1.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-streaming-kafka-0-8_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-streaming-kafka-0-8_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/datanucleus-rdbms-3.2.9.jar at spark://138.96.200.169:46353/jars/datanucleus-rdbms-3.2.9.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jul-to-slf4j-1.7.16.jar at spark://138.96.200.169:46353/jars/jul-to-slf4j-1.7.16.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/datanucleus-core-3.2.10.jar at spark://138.96.200.169:46353/jars/datanucleus-core-3.2.10.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hive-metastore-1.2.1.spark2.jar at spark://138.96.200.169:46353/jars/hive-metastore-1.2.1.spark2.jar with timestamp 1513618070082
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-annotations-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-annotations-2.6.5.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jodd-core-3.5.2.jar at spark://138.96.200.169:46353/jars/jodd-core-3.5.2.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/json4s-ast_2.11-3.2.11.jar at spark://138.96.200.169:46353/jars/json4s-ast_2.11-3.2.11.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-util-6.1.26.jar at spark://138.96.200.169:46353/jars/jetty-util-6.1.26.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-compress-1.4.1.jar at spark://138.96.200.169:46353/jars/commons-compress-1.4.1.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/zkclient-0.3.jar at spark://138.96.200.169:46353/jars/zkclient-0.3.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/macro-compat_2.11-1.1.1.jar at spark://138.96.200.169:46353/jars/macro-compat_2.11-1.1.1.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scala-xml_2.11-1.0.4.jar at spark://138.96.200.169:46353/jars/scala-xml_2.11-1.0.4.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scala-parser-combinators_2.11-1.0.4.jar at spark://138.96.200.169:46353/jars/scala-parser-combinators_2.11-1.0.4.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/eigenbase-properties-1.1.5.jar at spark://138.96.200.169:46353/jars/eigenbase-properties-1.1.5.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/xz-1.0.jar at spark://138.96.200.169:46353/jars/xz-1.0.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javax.ws.rs-api-2.0.1.jar at spark://138.96.200.169:46353/jars/javax.ws.rs-api-2.0.1.jar with timestamp 1513618070083
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/zookeeper-3.4.6.jar at spark://138.96.200.169:46353/jars/zookeeper-3.4.6.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/json4s-core_2.11-3.2.11.jar at spark://138.96.200.169:46353/jars/json4s-core_2.11-3.2.11.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-module-scala_2.11-2.6.5.jar at spark://138.96.200.169:46353/jars/jackson-module-scala_2.11-2.6.5.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/antlr4-runtime-4.5.3.jar at spark://138.96.200.169:46353/jars/antlr4-runtime-4.5.3.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-yarn-client-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-yarn-client-2.6.5.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/oro-2.0.8.jar at spark://138.96.200.169:46353/jars/oro-2.0.8.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/libthrift-0.9.3.jar at spark://138.96.200.169:46353/jars/libthrift-0.9.3.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-proxy-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-proxy-9.3.11.v20160721.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-beanutils-1.7.0.jar at spark://138.96.200.169:46353/jars/commons-beanutils-1.7.0.jar with timestamp 1513618070084
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/joda-time-2.9.3.jar at spark://138.96.200.169:46353/jars/joda-time-2.9.3.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/xbean-asm5-shaded-4.4.jar at spark://138.96.200.169:46353/jars/xbean-asm5-shaded-4.4.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/derby-10.12.1.1.jar at spark://138.96.200.169:46353/jars/derby-10.12.1.1.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jersey-server-2.22.2.jar at spark://138.96.200.169:46353/jars/jersey-server-2.22.2.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/kryo-shaded-3.0.3.jar at spark://138.96.200.169:46353/jars/kryo-shaded-3.0.3.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-math3-3.4.1.jar at spark://138.96.200.169:46353/jars/commons-math3-3.4.1.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/calcite-core-1.2.0-incubating.jar at spark://138.96.200.169:46353/jars/calcite-core-1.2.0-incubating.jar with timestamp 1513618070085
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-xml-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-xml-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-httpclient-3.1.jar at spark://138.96.200.169:46353/jars/commons-httpclient-3.1.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/opencsv-2.3.jar at spark://138.96.200.169:46353/jars/opencsv-2.3.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/xml-apis-1.3.04.jar at spark://138.96.200.169:46353/jars/xml-apis-1.3.04.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-servlets-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-servlets-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jetty-security-9.3.11.v20160721.jar at spark://138.96.200.169:46353/jars/jetty-security-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-core-2.6.5.jar at spark://138.96.200.169:46353/jars/jackson-core-2.6.5.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jline-0.9.94.jar at spark://138.96.200.169:46353/jars/jline-0.9.94.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/lz4-1.3.0.jar at spark://138.96.200.169:46353/jars/lz4-1.3.0.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/aopalliance-repackaged-2.4.0-b34.jar at spark://138.96.200.169:46353/jars/aopalliance-repackaged-2.4.0-b34.jar with timestamp 1513618070086
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-examples_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-examples_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/arpack_combined_all-0.1.jar at spark://138.96.200.169:46353/jars/arpack_combined_all-0.1.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-network-shuffle_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-network-shuffle_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/snappy-0.2.jar at spark://138.96.200.169:46353/jars/snappy-0.2.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/httpcore-4.4.4.jar at spark://138.96.200.169:46353/jars/httpcore-4.4.4.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/commons-codec-1.10.jar at spark://138.96.200.169:46353/jars/commons-codec-1.10.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jackson-jaxrs-1.9.13.jar at spark://138.96.200.169:46353/jars/jackson-jaxrs-1.9.13.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/snappy-java-1.1.2.6.jar at spark://138.96.200.169:46353/jars/snappy-java-1.1.2.6.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/breeze_2.11-0.13.2.jar at spark://138.96.200.169:46353/jars/breeze_2.11-0.13.2.jar with timestamp 1513618070087
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/flume-ng-configuration-1.6.0.jar at spark://138.96.200.169:46353/jars/flume-ng-configuration-1.6.0.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/javolution-5.5.1.jar at spark://138.96.200.169:46353/jars/javolution-5.5.1.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/kafka_2.11-0.8.2.1.jar at spark://138.96.200.169:46353/jars/kafka_2.11-0.8.2.1.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/netty-3.9.9.Final.jar at spark://138.96.200.169:46353/jars/netty-3.9.9.Final.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/machinist_2.11-0.6.1.jar at spark://138.96.200.169:46353/jars/machinist_2.11-0.6.1.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/scala-compiler-2.11.8.jar at spark://138.96.200.169:46353/jars/scala-compiler-2.11.8.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/parquet-jackson-1.8.2.jar at spark://138.96.200.169:46353/jars/parquet-jackson-1.8.2.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/leveldbjni-all-1.8.jar at spark://138.96.200.169:46353/jars/leveldbjni-all-1.8.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/stringtemplate-3.2.1.jar at spark://138.96.200.169:46353/jars/stringtemplate-3.2.1.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/apacheds-kerberos-codec-2.0.0-M15.jar at spark://138.96.200.169:46353/jars/apacheds-kerberos-codec-2.0.0-M15.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/calcite-avatica-1.2.0-incubating.jar at spark://138.96.200.169:46353/jars/calcite-avatica-1.2.0-incubating.jar with timestamp 1513618070088
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/spark-hive_2.11-2.2.2-SNAPSHOT.jar at spark://138.96.200.169:46353/jars/spark-hive_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-mapreduce-client-common-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-common-2.6.5.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/curator-framework-2.6.0.jar at spark://138.96.200.169:46353/jars/curator-framework-2.6.0.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/jta-1.1.jar at spark://138.96.200.169:46353/jars/jta-1.1.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/kafka-clients-0.10.0.1.jar at spark://138.96.200.169:46353/jars/kafka-clients-0.10.0.1.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/hadoop-mapreduce-client-core-2.6.5.jar at spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-core-2.6.5.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO SparkContext: Added JAR file:/workspaces/kderment/repos/spark/examples/target/scala-2.11/jars/log4j-1.2.17.jar at spark://138.96.200.169:46353/jars/log4j-1.2.17.jar with timestamp 1513618070089
17/12/18 18:27:50 INFO Executor: Starting executor ID driver on host localhost
17/12/18 18:27:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36769.
17/12/18 18:27:50 INFO NettyBlockTransferService: Server created on 138.96.200.169:36769
17/12/18 18:27:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/18 18:27:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 138.96.200.169, 36769, None)
17/12/18 18:27:50 INFO BlockManagerMasterEndpoint: Registering block manager 138.96.200.169:36769 with 366.3 MB RAM, BlockManagerId(driver, 138.96.200.169, 36769, None)
17/12/18 18:27:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 138.96.200.169, 36769, None)
17/12/18 18:27:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 138.96.200.169, 36769, None)
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5bfc257{/metrics/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/local/workspaces/kderment/repos/spark/spark-warehouse/').
17/12/18 18:27:50 INFO SharedState: Warehouse path is 'file:/local/workspaces/kderment/repos/spark/spark-warehouse/'.
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79ab34c1{/SQL,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@281f23f2{/SQL/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7435a578{/SQL/execution,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@13047d7d{/SQL/execution/json,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49601f82{/static/sql,null,AVAILABLE,@Spark}
17/12/18 18:27:50 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
17/12/18 18:27:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 216.6 KB, free 366.1 MB)
17/12/18 18:27:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 366.1 MB)
17/12/18 18:27:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 138.96.200.169:36769 (size: 20.5 KB, free: 366.3 MB)
17/12/18 18:27:51 INFO SparkContext: Created broadcast 0 from textFile at MLUtils.scala:99
17/12/18 18:27:51 INFO FileInputFormat: Total input paths to process : 1
17/12/18 18:27:51 INFO SparkContext: Starting job: reduce at MLUtils.scala:92
17/12/18 18:27:51 INFO DAGScheduler: Got job 0 (reduce at MLUtils.scala:92) with 8 output partitions
17/12/18 18:27:51 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
17/12/18 18:27:51 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:51 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   id: 0,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 0,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 5,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 5,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[5] at map at MLUtils.scala:90,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 4}
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 4,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[4] at map at MLUtils.scala:102,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 3}
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 3,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[3] at filter at MLUtils.scala:101,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 2}
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 2,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[2] at map at MLUtils.scala:100,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 1}
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 1,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt MapPartitionsRDD[1] at textFile at MLUtils.scala:99,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 0}
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     {id: 0,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      name: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt HadoopRDD[0] at textFile at MLUtils.scala:99,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      partitions_number: 8,
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:51 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 366.1 MB)
17/12/18 18:27:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.1 MB)
17/12/18 18:27:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 138.96.200.169:36769 (size: 2.3 KB, free: 366.3 MB)
17/12/18 18:27:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:51 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/18 18:27:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
17/12/18 18:27:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 4907 bytes)
17/12/18 18:27:51 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/12/18 18:27:51 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/12/18 18:27:51 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/12/18 18:27:51 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/12/18 18:27:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/12/18 18:27:51 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/12/18 18:27:51 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/12/18 18:27:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-collections-3.2.2.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO TransportClientFactory: Successfully created connection to /138.96.200.169:46353 after 28 ms (0 ms spent in bootstraps)
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-collections-3.2.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7288114963651876069.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-collections-3.2.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jline-0.9.94.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jline-0.9.94.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp682304350676034341.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jline-0.9.94.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/mina-core-2.0.4.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/mina-core-2.0.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5069598338275056003.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/mina-core-2.0.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/compress-lzf-1.0.3.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/compress-lzf-1.0.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3291633069372355298.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/compress-lzf-1.0.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/flume-ng-core-1.6.0.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/flume-ng-core-1.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4440908337582892030.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/flume-ng-core-1.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jta-1.1.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jta-1.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8042245247327341423.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jta-1.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/mx4j-3.0.2.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/mx4j-3.0.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp785613688341749497.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/mx4j-3.0.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/java-xmlbuilder-1.0.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/java-xmlbuilder-1.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8894615754998069573.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/java-xmlbuilder-1.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/calcite-linq4j-1.2.0-incubating.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/calcite-linq4j-1.2.0-incubating.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp991387902522673996.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/calcite-linq4j-1.2.0-incubating.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-util-6.1.26.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-util-6.1.26.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp368760000339721400.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-util-6.1.26.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/aopalliance-1.0.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/aopalliance-1.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4931963041093365231.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/aopalliance-1.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/macro-compat_2.11-1.1.1.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/macro-compat_2.11-1.1.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1626170901059166027.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/macro-compat_2.11-1.1.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/curator-recipes-2.6.0.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/curator-recipes-2.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp91146803545788827.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/curator-recipes-2.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-server-2.22.2.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-server-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4263023771861934952.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-server-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-codec-1.10.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-codec-1.10.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3933270452377705030.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-codec-1.10.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scopt_2.11-3.3.0.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scopt_2.11-3.3.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4755606029982611657.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scopt_2.11-3.3.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javassist-3.18.1-GA.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javassist-3.18.1-GA.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4526757587256089700.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javassist-3.18.1-GA.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/libthrift-0.9.3.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/libthrift-0.9.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4152932220425856484.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/libthrift-0.9.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-util-9.3.11.v20160721.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-util-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5970162011176794283.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-util-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/xercesImpl-2.9.1.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/xercesImpl-2.9.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4094050211039046920.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/xercesImpl-2.9.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-mllib_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-mllib_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7173023475619406710.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-mllib_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-unsafe_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-unsafe_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4214224452854088022.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-unsafe_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/api-util-1.0.0-M20.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/api-util-1.0.0-M20.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6763077772716660302.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/api-util-1.0.0-M20.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javax.inject-2.4.0-b34.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javax.inject-2.4.0-b34.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4842437983639929976.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javax.inject-2.4.0-b34.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-proxy-9.3.11.v20160721.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-proxy-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp717770186876520231.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-proxy-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/pmml-schema-1.2.15.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/pmml-schema-1.2.15.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp845215569090371067.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/pmml-schema-1.2.15.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-client-2.6.5.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-client-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2097427718902586321.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-client-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-server-common-2.6.5.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-server-common-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8359939082151746294.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-yarn-server-common-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/protobuf-java-2.5.0.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/protobuf-java-2.5.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp709755582972400154.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/protobuf-java-2.5.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-servlet-9.3.11.v20160721.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-servlet-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3611644265995877684.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-servlet-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spire-macros_2.11-0.13.0.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spire-macros_2.11-0.13.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2543458035506183649.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spire-macros_2.11-0.13.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/metrics-core-2.2.0.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/metrics-core-2.2.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3396511738202033747.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/metrics-core-2.2.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-app-2.6.5.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-app-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2022878000871996526.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-mapreduce-client-app-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/stringtemplate-3.2.1.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/stringtemplate-3.2.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4138053535659253874.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/stringtemplate-3.2.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/calcite-core-1.2.0-incubating.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/calcite-core-1.2.0-incubating.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7608978612559505573.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/calcite-core-1.2.0-incubating.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/antlr4-runtime-4.5.3.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/antlr4-runtime-4.5.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7563794161971545097.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/antlr4-runtime-4.5.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/janino-3.0.7.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/janino-3.0.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4224848884667685386.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/janino-3.0.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jul-to-slf4j-1.7.16.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jul-to-slf4j-1.7.16.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8724498421224964875.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jul-to-slf4j-1.7.16.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/apacheds-i18n-2.0.0-M15.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/apacheds-i18n-2.0.0-M15.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6175437769570819882.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/apacheds-i18n-2.0.0-M15.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/stream-2.7.0.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/stream-2.7.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp127378178389378822.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/stream-2.7.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/xml-apis-1.3.04.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/xml-apis-1.3.04.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6573537795820277179.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/xml-apis-1.3.04.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-sql-kafka-0-10_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-sql-kafka-0-10_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp451280840877993375.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-sql-kafka-0-10_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/bonecp-0.8.0.RELEASE.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/bonecp-0.8.0.RELEASE.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7186684178998167276.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/bonecp-0.8.0.RELEASE.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-dbcp-1.4.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-dbcp-1.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp573154126982783451.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-dbcp-1.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-compress-1.4.1.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-compress-1.4.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7330461417833565982.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-compress-1.4.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/avro-compiler-1.7.3.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/avro-compiler-1.7.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3771561575834436083.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/avro-compiler-1.7.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/eigenbase-properties-1.1.5.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/eigenbase-properties-1.1.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp365923382002120961.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/eigenbase-properties-1.1.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jdo-api-3.0.1.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jdo-api-3.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1667874979190693638.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jdo-api-3.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-server-9.3.11.v20160721.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-server-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp928516723845552346.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-server-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/chill-java-0.8.0.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/chill-java-0.8.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4014380845685881296.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/chill-java-0.8.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-guava-2.22.2.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-guava-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp796366408904933443.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-guava-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/kafka-clients-0.10.0.1.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/kafka-clients-0.10.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5639613973242131853.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/kafka-clients-0.10.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/kafka_2.11-0.8.2.1.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/kafka_2.11-0.8.2.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1231708594805594984.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/kafka_2.11-0.8.2.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/activation-1.1.1.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/activation-1.1.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6133107390543710459.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/activation-1.1.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/snappy-0.2.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/snappy-0.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8203976062654595098.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/snappy-0.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-format-2.3.1.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-format-2.3.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5093074049005374541.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-format-2.3.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1680457455405600947.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-mapreduce-client-jobclient-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scalap-2.11.8.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scalap-2.11.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2528793931419407651.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scalap-2.11.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-media-jaxb-2.22.2.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-media-jaxb-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8691688282317043975.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-media-jaxb-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/avro-ipc-1.7.7.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/avro-ipc-1.7.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4786128893267492263.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/avro-ipc-1.7.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jcl-over-slf4j-1.7.16.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jcl-over-slf4j-1.7.16.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1464489064341838173.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jcl-over-slf4j-1.7.16.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javax.annotation-api-1.2.jar with timestamp 1513618070067
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javax.annotation-api-1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3780148043281818014.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javax.annotation-api-1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-auth-2.6.5.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-auth-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2401264659798915594.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-auth-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/servlet-api-2.5-20110124.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/servlet-api-2.5-20110124.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5670083387694340393.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/servlet-api-2.5-20110124.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/curator-framework-2.6.0.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/curator-framework-2.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6092474371756248931.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/curator-framework-2.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-cli-1.2.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-cli-1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5552706619492056951.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-cli-1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-beanutils-1.7.0.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-beanutils-1.7.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6558166928908533141.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-beanutils-1.7.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-core-asl-1.9.13.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-core-asl-1.9.13.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3222676514059107501.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-core-asl-1.9.13.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/chill_2.11-0.8.0.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/chill_2.11-0.8.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4953660579832193150.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/chill_2.11-0.8.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/json4s-core_2.11-3.2.11.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/json4s-core_2.11-3.2.11.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2292587646214428637.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/json4s-core_2.11-3.2.11.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/xz-1.0.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/xz-1.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6076066838107738277.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/xz-1.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/avro-ipc-1.7.7-tests.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/avro-ipc-1.7.7-tests.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8473522242790940611.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/avro-ipc-1.7.7-tests.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-catalyst_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-catalyst_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6189321146617815375.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-catalyst_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-annotations-2.6.5.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-annotations-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7659965491972449183.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-annotations-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/flume-ng-sdk-1.6.0.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/flume-ng-sdk-1.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6238462911428692727.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/flume-ng-sdk-1.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/ivy-2.4.0.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/ivy-2.4.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5836096125341812013.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/ivy-2.4.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-streaming-flume-sink_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-streaming-flume-sink_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8121861025036871058.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-streaming-flume-sink_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-core_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-core_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1282107619498802652.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-core_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-client-2.22.2.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-client-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp9116870271474681186.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-client-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/metrics-graphite-3.1.2.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/metrics-graphite-3.1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1689548673232502371.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/metrics-graphite-3.1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javax.inject-1.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javax.inject-1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5048139442401801659.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javax.inject-1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-network-shuffle_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-network-shuffle_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4338467848177265604.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-network-shuffle_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/aopalliance-repackaged-2.4.0-b34.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/aopalliance-repackaged-2.4.0-b34.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5096407264258625015.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/aopalliance-repackaged-2.4.0-b34.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/unused-1.0.0.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/unused-1.0.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7511155191150095003.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/unused-1.0.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/avro-mapred-1.7.7-hadoop2.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/avro-mapred-1.7.7-hadoop2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3610131052944513047.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/avro-mapred-1.7.7-hadoop2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-tags_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-tags_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2899476020523333407.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-tags_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/flume-ng-configuration-1.6.0.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/flume-ng-configuration-1.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2868386574773815812.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/flume-ng-configuration-1.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-xml-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-xml-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7544706352818474540.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-xml-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-api-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-api-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8588513624551183072.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-yarn-api-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-beanutils-core-1.8.0.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-beanutils-core-1.8.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6969136263299362192.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-beanutils-core-1.8.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-streaming-kafka-0-8_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-streaming-kafka-0-8_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6501796415584429560.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-streaming-kafka-0-8_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/avro-1.7.7.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/avro-1.7.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6475539052390845379.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/avro-1.7.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-annotations-2.6.5.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-annotations-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2536843374657725383.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-annotations-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hk2-utils-2.4.0-b34.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hk2-utils-2.4.0-b34.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6092735038069006725.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hk2-utils-2.4.0-b34.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/zookeeper-3.4.6.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/zookeeper-3.4.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3272756109230982320.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/zookeeper-3.4.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/kryo-shaded-3.0.3.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/kryo-shaded-3.0.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8696803468428475475.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/kryo-shaded-3.0.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-sketch_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-sketch_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7734634575333984954.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-sketch_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-pool-1.5.4.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-pool-1.5.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2731486283343208598.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-pool-1.5.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-http-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-http-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4277024932111175031.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-http-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/bcprov-jdk15on-1.51.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/bcprov-jdk15on-1.51.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp479540461214888465.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/bcprov-jdk15on-1.51.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/osgi-resource-locator-1.0.1.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/osgi-resource-locator-1.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7581456588423846456.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/osgi-resource-locator-1.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/validation-api-1.1.0.Final.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/validation-api-1.1.0.Final.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5527016327567180398.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/validation-api-1.1.0.Final.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/antlr-runtime-3.4.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/antlr-runtime-3.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp806392369997763041.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/antlr-runtime-3.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-mapper-asl-1.9.13.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-mapper-asl-1.9.13.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp411813393735036095.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-mapper-asl-1.9.13.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/opencsv-2.3.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/opencsv-2.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3872767552882740207.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/opencsv-2.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/apacheds-kerberos-codec-2.0.0-M15.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/apacheds-kerberos-codec-2.0.0-M15.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7229116861766322009.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/apacheds-kerberos-codec-2.0.0-M15.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/minlog-1.3.0.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/minlog-1.3.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5317576880239486238.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/minlog-1.3.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scala-library-2.11.8.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scala-library-2.11.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6596002034413550825.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scala-library-2.11.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/datanucleus-api-jdo-3.2.6.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/datanucleus-api-jdo-3.2.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp9104636567332484350.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/datanucleus-api-jdo-3.2.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javolution-5.5.1.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javolution-5.5.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2262273855914750912.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javolution-5.5.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5968803767058721781.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-mapreduce-client-shuffle-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-core-2.6.5.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-core-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3431495566329098322.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-mapreduce-client-core-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-jndi-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-jndi-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6369227901682949603.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-jndi-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-compiler-3.0.7.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-compiler-3.0.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2790257566228333091.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-compiler-3.0.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-common-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-common-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8301332115126602467.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-yarn-common-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/shapeless_2.11-2.3.2.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/shapeless_2.11-2.3.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8418202962446434852.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/shapeless_2.11-2.3.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/joda-time-2.9.3.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/joda-time-2.9.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2152472568700430797.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/joda-time-2.9.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-common-2.6.5.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-mapreduce-client-common-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp678551368281727357.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-mapreduce-client-common-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/apache-log4j-extras-1.2.17.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/apache-log4j-extras-1.2.17.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6524760622288533638.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/apache-log4j-extras-1.2.17.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-servlets-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-servlets-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6957954728822118658.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-servlets-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/json4s-jackson_2.11-3.2.11.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/json4s-jackson_2.11-3.2.11.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7415632115501086491.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/json4s-jackson_2.11-3.2.11.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/curator-client-2.6.0.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/curator-client-2.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7259555165938610515.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/curator-client-2.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-security-9.3.11.v20160721.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-security-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1694078383903973537.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-security-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/RoaringBitmap-0.5.11.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/RoaringBitmap-0.5.11.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7554819792362054302.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/RoaringBitmap-0.5.11.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/flume-ng-auth-1.6.0.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/flume-ng-auth-1.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8160563594077577949.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/flume-ng-auth-1.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/objenesis-2.1.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/objenesis-2.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8529885091113712449.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/objenesis-2.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/core-1.1.2.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/core-1.1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2222760834923715360.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/core-1.1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/log4j-1.2.17.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/log4j-1.2.17.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5321175370037055847.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/log4j-1.2.17.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/metrics-jvm-3.1.2.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/metrics-jvm-3.1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2279296961139966248.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/metrics-jvm-3.1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/metrics-json-3.1.2.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/metrics-json-3.1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5829348370997788306.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/metrics-json-3.1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/lz4-1.3.0.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/lz4-1.3.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp543599428288338085.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/lz4-1.3.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javax.servlet-api-3.1.0.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javax.servlet-api-3.1.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1221780641382437287.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javax.servlet-api-3.1.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-column-1.8.2.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-column-1.8.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7221537328547840968.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-column-1.8.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/machinist_2.11-0.6.1.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/machinist_2.11-0.6.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8753560311141743573.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/machinist_2.11-0.6.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/datanucleus-rdbms-3.2.9.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/datanucleus-rdbms-3.2.9.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1473631686427655870.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/datanucleus-rdbms-3.2.9.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jaxb-api-2.2.2.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jaxb-api-2.2.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7273818760321372148.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jaxb-api-2.2.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/antlr-2.7.7.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/antlr-2.7.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7594991285458387196.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/antlr-2.7.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-container-servlet-core-2.22.2.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-container-servlet-core-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5722750581667131434.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-container-servlet-core-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-common-2.6.5.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-common-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8400760881093829835.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-common-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-module-scala_2.11-2.6.5.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-module-scala_2.11-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4517036841966422348.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-module-scala_2.11-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/oro-2.0.8.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/oro-2.0.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3317758999520504722.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/oro-2.0.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-plus-9.3.11.v20160721.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-plus-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1684204031664367418.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-plus-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jets3t-0.9.3.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jets3t-0.9.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3397031288085957032.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jets3t-0.9.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/pyrolite-4.13.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/pyrolite-4.13.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6869600696494276530.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/pyrolite-4.13.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/xbean-asm5-shaded-4.4.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/xbean-asm5-shaded-4.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5092065128306461671.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/xbean-asm5-shaded-4.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-hdfs-2.6.5.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-hdfs-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2668792536300781678.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-hdfs-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/metrics-core-3.1.2.jar with timestamp 1513618070077
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/metrics-core-3.1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7721577355522504024.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/metrics-core-3.1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/pmml-model-1.2.15.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/pmml-model-1.2.15.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4011245491542360687.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/pmml-model-1.2.15.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spire_2.11-0.13.0.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spire_2.11-0.13.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8368884395806981398.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spire_2.11-0.13.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-hive_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070089
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-hive_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2462317546231945066.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-hive_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/javax.ws.rs-api-2.0.1.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/javax.ws.rs-api-2.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3638352302146972836.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/javax.ws.rs-api-2.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-lang-2.6.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-lang-2.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp789373981504501871.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-lang-2.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scala-reflect-2.11.8.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scala-reflect-2.11.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3264788971732133188.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scala-reflect-2.11.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-streaming-flume_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-streaming-flume_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6403047564263896910.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-streaming-flume_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-databind-2.6.5.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-databind-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp596790481479069540.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-databind-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/htrace-core-3.0.4.jar with timestamp 1513618070067
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/htrace-core-3.0.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2213831060045022850.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/htrace-core-3.0.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-continuation-9.3.11.v20160721.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-continuation-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8354287215730496232.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-continuation-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-net-3.1.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-net-3.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6448888483595240900.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-net-3.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-xc-1.9.13.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-xc-1.9.13.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8654076831557085625.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-xc-1.9.13.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hive-exec-1.2.1.spark2.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hive-exec-1.2.1.spark2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7349939034407873000.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hive-exec-1.2.1.spark2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/libfb303-0.9.3.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/libfb303-0.9.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1398947317384370738.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/libfb303-0.9.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jettison-1.1.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jettison-1.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3275060237736711242.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jettison-1.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/api-asn1-api-1.0.0-M20.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/api-asn1-api-1.0.0-M20.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5828528185139965227.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/api-asn1-api-1.0.0-M20.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-6.1.26.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-6.1.26.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7190255379778443088.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-6.1.26.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-sql_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-sql_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1594072061632348088.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-sql_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/mail-1.4.7.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/mail-1.4.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5350251550066479109.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/mail-1.4.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/httpcore-4.4.4.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/httpcore-4.4.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2865324904672155464.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/httpcore-4.4.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-jaxrs-1.9.13.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-jaxrs-1.9.13.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8849044230986328485.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-jaxrs-1.9.13.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-common-1.8.2.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-common-1.8.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4744026815443475022.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-common-1.8.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-configuration-1.6.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-configuration-1.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3413159690871216374.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-configuration-1.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-io-9.3.11.v20160721.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-io-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2273138718875171501.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-io-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/cglib-2.2.1-v20090111.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/cglib-2.2.1-v20090111.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6963456901629464608.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/cglib-2.2.1-v20090111.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-mllib-local_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-mllib-local_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2321245238725892863.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-mllib-local_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scala-parser-combinators_2.11-1.0.4.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4555835194780827256.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scala-parser-combinators_2.11-1.0.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/snappy-java-1.1.2.6.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/snappy-java-1.1.2.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8235891983012141477.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/snappy-java-1.1.2.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/stax-api-1.0.1.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/stax-api-1.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7563045163819815052.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/stax-api-1.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jtransforms-2.4.0.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jtransforms-2.4.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp563831390279885534.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jtransforms-2.4.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-client-9.3.11.v20160721.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-client-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6954029160775333397.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-client-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/ST4-4.0.4.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/ST4-4.0.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7188261034574689997.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/ST4-4.0.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-launcher_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070070
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-launcher_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp9204410897978850524.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-launcher_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-client-2.6.5.jar with timestamp 1513618070084
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hadoop-yarn-client-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7079722882052605652.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hadoop-yarn-client-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scala-xml_2.11-1.0.4.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scala-xml_2.11-1.0.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5668503095917245002.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scala-xml_2.11-1.0.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-common-2.22.2.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-common-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7971220846856447481.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-common-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-jackson-1.8.2.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-jackson-1.8.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5111342198947773229.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-jackson-1.8.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-hadoop-1.8.2.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-hadoop-1.8.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2415369209753842846.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-hadoop-1.8.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-core-2.6.5.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-core-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1728070356902508158.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-core-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/datanucleus-core-3.2.10.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/datanucleus-core-3.2.10.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8923621408751014528.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/datanucleus-core-3.2.10.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jodd-core-3.5.2.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jodd-core-3.5.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp585622961798069986.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jodd-core-3.5.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-network-common_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-network-common_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2304869555547672101.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-network-common_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/xmlenc-0.52.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/xmlenc-0.52.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3590552157486787788.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/xmlenc-0.52.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-lang3-3.5.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-lang3-3.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1635532768394124774.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-lang3-3.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hk2-locator-2.4.0-b34.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hk2-locator-2.4.0-b34.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3484428587226209061.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hk2-locator-2.4.0-b34.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-encoding-1.8.2.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-encoding-1.8.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5095335477985746223.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-encoding-1.8.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-crypto-1.0.0.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-crypto-1.0.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4193234336361557077.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-crypto-1.0.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/arpack_combined_all-0.1.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/arpack_combined_all-0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5838711331548754357.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/arpack_combined_all-0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-logging-1.2.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-logging-1.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1845385728534305317.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-logging-1.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/parquet-hadoop-bundle-1.6.0.jar with timestamp 1513618070076
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/parquet-hadoop-bundle-1.6.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6424954399680875430.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/parquet-hadoop-bundle-1.6.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/derby-10.12.1.1.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/derby-10.12.1.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2862466306110578661.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/derby-10.12.1.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hk2-api-2.4.0-b34.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hk2-api-2.4.0-b34.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8403583422135089358.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hk2-api-2.4.0-b34.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/netty-3.9.9.Final.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/netty-3.9.9.Final.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6350478410083631586.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/netty-3.9.9.Final.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/breeze_2.11-0.13.2.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/breeze_2.11-0.13.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp486163592019275506.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/breeze_2.11-0.13.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/velocity-1.7.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/velocity-1.7.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4350826514965565087.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/velocity-1.7.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/netty-all-4.0.43.Final.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/netty-all-4.0.43.Final.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5766512532018075793.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/netty-all-4.0.43.Final.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/py4j-0.10.4.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/py4j-0.10.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp149037080786827585.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/py4j-0.10.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/stax-api-1.0-2.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/stax-api-1.0-2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8714065425791220016.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/stax-api-1.0-2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/guice-3.0.jar with timestamp 1513618070078
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/guice-3.0.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1134905531216783609.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/guice-3.0.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/gson-2.2.4.jar with timestamp 1513618070074
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/gson-2.2.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8451651801167943295.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/gson-2.2.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-math3-3.4.1.jar with timestamp 1513618070085
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-math3-3.4.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5483928312858499019.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-math3-3.4.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/zkclient-0.3.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/zkclient-0.3.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3062935420778446716.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/zkclient-0.3.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/paranamer-2.6.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/paranamer-2.6.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6495680546240242594.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/paranamer-2.6.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/slf4j-log4j12-1.7.16.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/slf4j-log4j12-1.7.16.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6651365018020142690.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/slf4j-log4j12-1.7.16.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-streaming_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070067
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-streaming_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8201716989605771645.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-streaming_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jsr305-1.3.9.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jsr305-1.3.9.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1373497071956936498.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jsr305-1.3.9.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/breeze-macros_2.11-0.13.2.jar with timestamp 1513618070068
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/breeze-macros_2.11-0.13.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8763525055010462724.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/breeze-macros_2.11-0.13.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/guava-14.0.1.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/guava-14.0.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6147798393140217262.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/guava-14.0.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-graphx_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-graphx_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp8325562508866339422.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-graphx_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/base64-2.3.8.jar with timestamp 1513618070080
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/base64-2.3.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4764960138937425037.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/base64-2.3.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-digester-1.8.jar with timestamp 1513618070075
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-digester-1.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1685578199443701669.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-digester-1.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jersey-container-servlet-2.22.2.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jersey-container-servlet-2.22.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7970383169647707121.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jersey-container-servlet-2.22.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/calcite-avatica-1.2.0-incubating.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/calcite-avatica-1.2.0-incubating.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6335208775538534927.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/calcite-avatica-1.2.0-incubating.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jackson-module-paranamer-2.6.5.jar with timestamp 1513618070071
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jackson-module-paranamer-2.6.5.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7732549680418870238.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jackson-module-paranamer-2.6.5.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/slf4j-api-1.7.21.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/slf4j-api-1.7.21.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7968750164471778725.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/slf4j-api-1.7.21.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-io-2.4.jar with timestamp 1513618070073
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-io-2.4.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4806687589752156850.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-io-2.4.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/json4s-ast_2.11-3.2.11.jar with timestamp 1513618070083
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/json4s-ast_2.11-3.2.11.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp7861834593552608298.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/json4s-ast_2.11-3.2.11.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/jetty-webapp-9.3.11.v20160721.jar with timestamp 1513618070081
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/jetty-webapp-9.3.11.v20160721.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp952214715160057912.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/jetty-webapp-9.3.11.v20160721.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/univocity-parsers-2.2.1.jar with timestamp 1513618070079
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/univocity-parsers-2.2.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp5635346832968899272.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/univocity-parsers-2.2.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/hive-metastore-1.2.1.spark2.jar with timestamp 1513618070082
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/hive-metastore-1.2.1.spark2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp4088713415397217448.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/hive-metastore-1.2.1.spark2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/spark-examples_2.11-2.2.2-SNAPSHOT.jar with timestamp 1513618070087
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/spark-examples_2.11-2.2.2-SNAPSHOT.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp3635904622714377611.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/spark-examples_2.11-2.2.2-SNAPSHOT.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/commons-httpclient-3.1.jar with timestamp 1513618070086
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/commons-httpclient-3.1.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp2137867945238655044.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/commons-httpclient-3.1.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/JavaEWAH-0.3.2.jar with timestamp 1513618070069
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/JavaEWAH-0.3.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp6156021902823646810.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/JavaEWAH-0.3.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/scala-compiler-2.11.8.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/scala-compiler-2.11.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp258961174041839643.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/scala-compiler-2.11.8.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/httpclient-4.5.2.jar with timestamp 1513618070072
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/httpclient-4.5.2.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp1089305120910136376.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/httpclient-4.5.2.jar to class loader
17/12/18 18:27:51 INFO Executor: Fetching spark://138.96.200.169:46353/jars/leveldbjni-all-1.8.jar with timestamp 1513618070088
17/12/18 18:27:51 INFO Utils: Fetching spark://138.96.200.169:46353/jars/leveldbjni-all-1.8.jar to /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/fetchFileTemp922034209299938278.tmp
17/12/18 18:27:51 INFO Executor: Adding file:/tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193/userFiles-4dbbc65a-e648-4d90-b554-88f3f417c188/leveldbjni-all-1.8.jar to class loader
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:104181+14888
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:89298+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:29766+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:0+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:14883+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:74415+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:44649+14883
17/12/18 18:27:52 INFO HadoopRDD: Input split: file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt:59532+14883
17/12/18 18:27:52 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 953 bytes result sent to driver
17/12/18 18:27:52 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 953 bytes result sent to driver
17/12/18 18:27:52 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 853 ms on localhost (executor driver) (1/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 856 ms on localhost (executor driver) (2/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 867 ms on localhost (executor driver) (3/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 858 ms on localhost (executor driver) (4/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 856 ms on localhost (executor driver) (5/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 856 ms on localhost (executor driver) (6/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 857 ms on localhost (executor driver) (7/8)
17/12/18 18:27:52 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 858 ms on localhost (executor driver) (8/8)
17/12/18 18:27:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/18 18:27:52 INFO DAGScheduler: ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.884 s
17/12/18 18:27:52 INFO DAGScheduler: Job 0 finished: reduce at MLUtils.scala:92, took 0.973846 s
17/12/18 18:27:53 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 138.96.200.169:36769 in memory (size: 2.3 KB, free: 366.3 MB)
17/12/18 18:27:53 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 138.96.200.169:36769 in memory (size: 20.5 KB, free: 366.3 MB)
17/12/18 18:27:53 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:53 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:53 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:53 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 170.553544 ms
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 308.6 KB, free 366.0 MB)
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.3 KB, free 366.0 MB)
17/12/18 18:27:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 366.3 MB)
17/12/18 18:27:53 INFO SparkContext: Created broadcast 2 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:53 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:53 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: {"trainRatio":0.8}
17/12/18 18:27:53 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: {"estimator":"org.apache.spark.ml.regression.LinearRegression"}
17/12/18 18:27:53 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: {"evaluator":"org.apache.spark.ml.evaluation.RegressionEvaluator"}
17/12/18 18:27:53 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: {"estimatorParamMapsLength":12}
17/12/18 18:27:53 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:53 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:53 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:53 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 39.487649 ms
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 308.6 KB, free 365.7 MB)
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.3 KB, free 365.6 MB)
17/12/18 18:27:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 366.2 MB)
17/12/18 18:27:53 INFO SparkContext: Created broadcast 3 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:53 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:53 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:53 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:53 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 34.23088 ms
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 308.6 KB, free 365.3 MB)
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.3 KB, free 365.3 MB)
17/12/18 18:27:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 366.2 MB)
17/12/18 18:27:53 INFO SparkContext: Created broadcast 4 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 8.65873 ms
17/12/18 18:27:53 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:53 INFO DAGScheduler: Got job 1 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:53 INFO DAGScheduler: Final stage: ResultStage 1 (first at LinearRegression.scala:198)
17/12/18 18:27:53 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:53 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:53 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[17] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   id: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 17,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     {id: 17,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[17] at first at LinearRegression.scala:198,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 16}
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     {id: 16,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[16] at first at LinearRegression.scala:198,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:53 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.9 KB, free 365.3 MB)
17/12/18 18:27:53 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.3 MB)
17/12/18 18:27:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 138.96.200.169:36769 (size: 11.0 KB, free: 366.2 MB)
17/12/18 18:27:53 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/18 18:27:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 8)
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 28.410761 ms
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 13.217143 ms
17/12/18 18:27:53 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 13.212463 ms
17/12/18 18:27:53 INFO CodeGenerator: Code generated in 24.717906 ms
17/12/18 18:27:54 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 70.9 KB, free 365.2 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added rdd_12_0 in memory on 138.96.200.169:36769 (size: 70.9 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 4.059459 ms
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 14.880374 ms
17/12/18 18:27:54 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_12_0]
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 8). 3091 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 8) in 271 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 1 (first at LinearRegression.scala:198) finished in 0.273 s
17/12/18 18:27:54 INFO DAGScheduler: Job 1 finished: first at LinearRegression.scala:198, took 0.297463 s
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 14.087381 ms
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-1147820709-2: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-1147820709-2: {"elasticNetParam":0.0,"fitIntercept":true,"maxIter":10,"regParam":0.1}
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-1147820709-2: {"numFeatures":10}
17/12/18 18:27:54 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:54 INFO DAGScheduler: Got job 2 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 2 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[26] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 2,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 2,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 26,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 26,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[26] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 22}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 22,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[22] at map at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 21}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 21,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[21] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 20}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 20,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[20] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 19}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 19,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[19] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 18}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 18,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[18] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.0 KB, free 365.2 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.0 KB, free 365.2 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[26] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO ContextCleaner: Cleaned accumulator 85
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/18 18:27:54 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 138.96.200.169:36769 in memory (size: 11.0 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 14.048479 ms
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 7.243859 ms
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 3340 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 49 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 2 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.050 s
17/12/18 18:27:54 INFO DAGScheduler: Job 2 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.075434 s
17/12/18 18:27:54 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/12/18 18:27:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/12/18 18:27:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
17/12/18 18:27:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 14.672592 ms
17/12/18 18:27:54 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:54 INFO DAGScheduler: Got job 3 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 3 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[32] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 3,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 3,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 32,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 32,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[32] at map at RegressionMetrics.scala:55,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 31}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 31,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[31] at map at LinearRegression.scala:632,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 30}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 30,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[30] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 29}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 29,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[29] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 28}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 28,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[28] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 27}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 27,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[27] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.7 KB, free 365.2 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.1 KB, free 365.1 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[32] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 11.967171 ms
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 5.994935 ms
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 2833 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 40 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 3 (aggregate at RegressionMetrics.scala:57) finished in 0.041 s
17/12/18 18:27:54 INFO DAGScheduler: Job 3 finished: aggregate at RegressionMetrics.scala:57, took 0.049081 s
17/12/18 18:27:54 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:54 INFO DAGScheduler: Got job 4 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 4 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[33] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 4,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 4,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 33,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 33,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[33] at map at RegressionMetrics.scala:69,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 31}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 31,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[31] at map at LinearRegression.scala:632,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 30}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 30,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[30] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 29}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 29,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[29] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 28}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 28,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[28] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 27}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 27,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[27] at rdd at LinearRegression.scala:631,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 39.3 KB, free 365.1 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 16.0 KB, free 365.1 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[33] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 2307 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 13 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 4 (sum at RegressionMetrics.scala:71) finished in 0.014 s
17/12/18 18:27:54 INFO DAGScheduler: Job 4 finished: sum at RegressionMetrics.scala:71, took 0.023564 s
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 6.638045 ms
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 6.621353 ms
17/12/18 18:27:54 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:54 INFO DAGScheduler: Registering RDD 36 (count at LinearRegression.scala:696)
17/12/18 18:27:54 INFO DAGScheduler: Got job 5 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 6 (count at LinearRegression.scala:696)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/18 18:27:54 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[36] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 5,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 5,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 36,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 36,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[36] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 35}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 35,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[35] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 34}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 34,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[34] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 32.8 KB, free 365.1 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.7 KB, free 365.0 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[36] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 5.0 (TID 12)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO CodeGenerator: Code generated in 11.53282 ms
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 12). 2748 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 12) in 48 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ShuffleMapStage 5 (count at LinearRegression.scala:696) finished in 0.048 s
17/12/18 18:27:54 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:54 INFO DAGScheduler: running: Set()
17/12/18 18:27:54 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/18 18:27:54 INFO DAGScheduler: failed: Set()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 6,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 6,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 39,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 39,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[39] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 38}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 38,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[38] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 37}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 37,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[37] at count at LinearRegression.scala:696,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 36}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 365.0 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.0 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 6.0 (TID 13)
17/12/18 18:27:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 6.0 (TID 13). 1581 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 13) in 32 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 6 (count at LinearRegression.scala:696) finished in 0.033 s
17/12/18 18:27:54 INFO DAGScheduler: Job 5 finished: count at LinearRegression.scala:696, took 0.107974 s
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-1147820709-2: training finished
17/12/18 18:27:54 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:54 INFO DAGScheduler: Got job 6 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 7 (first at LinearRegression.scala:198)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[41] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 7,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 7,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 41,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 41,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[41] at first at LinearRegression.scala:198,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 40}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 40,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[40] at first at LinearRegression.scala:198,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.9 KB, free 365.0 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.1 KB, free 365.0 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[41] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 14)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_12_0]
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 7.0 (TID 14). 2367 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 7 (first at LinearRegression.scala:198) finished in 0.007 s
17/12/18 18:27:54 INFO DAGScheduler: Job 6 finished: first at LinearRegression.scala:198, took 0.012769 s
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-836570670-3: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-836570670-3: {"elasticNetParam":0.0,"fitIntercept":true,"maxIter":10,"regParam":0.01}
17/12/18 18:27:54 INFO Instrumentation: LinearRegression-linReg_be181b167431-836570670-3: {"numFeatures":10}
17/12/18 18:27:54 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:54 INFO DAGScheduler: Got job 7 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:54 INFO DAGScheduler: Final stage: ResultStage 8 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:54 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:54 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:54 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[50] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   id: 8,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 8,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 50,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 50,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[50] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 46}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 46,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[46] at map at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 45}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 45,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[45] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 44}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 44,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[44] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 43}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 43,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[43] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 42}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 42,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[42] at rdd at LinearRegression.scala:202,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:54 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 39.0 KB, free 365.0 MB)
17/12/18 18:27:54 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.9 MB)
17/12/18 18:27:54 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:54 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[50] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:54 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/18 18:27:54 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:54 INFO Executor: Running task 0.0 in stage 8.0 (TID 15)
17/12/18 18:27:54 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:54 INFO Executor: Finished task 0.0 in stage 8.0 (TID 15). 3297 bytes result sent to driver
17/12/18 18:27:54 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 15) in 14 ms on localhost (executor driver) (1/1)
17/12/18 18:27:54 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/18 18:27:54 INFO DAGScheduler: ResultStage 8 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.014 s
17/12/18 18:27:54 INFO DAGScheduler: Job 7 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.020278 s
17/12/18 18:27:54 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:55 INFO DAGScheduler: Got job 8 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 9 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[56] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 9,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 9,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 56,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 56,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[56] at map at RegressionMetrics.scala:55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 55}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[55] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 54}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 54,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[54] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 53}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 53,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[53] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 52}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 52,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[52] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 51}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 51,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[51] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.7 KB, free 364.9 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.9 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[56] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 9.0 (TID 16)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 9.0 (TID 16). 2790 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 16) in 10 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 9 (aggregate at RegressionMetrics.scala:57) finished in 0.011 s
17/12/18 18:27:55 INFO DAGScheduler: Job 8 finished: aggregate at RegressionMetrics.scala:57, took 0.019578 s
17/12/18 18:27:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:55 INFO DAGScheduler: Got job 9 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 10 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[57] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 57,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 57,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[57] at map at RegressionMetrics.scala:69,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 55}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[55] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 54}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 54,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[54] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 53}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 53,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[53] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 52}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 52,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[52] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 51}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 51,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[51] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[57] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 10.0 (TID 17)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 10.0 (TID 17). 2307 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 17) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 10 (sum at RegressionMetrics.scala:71) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 9 finished: sum at RegressionMetrics.scala:71, took 0.013729 s
17/12/18 18:27:55 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:55 INFO DAGScheduler: Registering RDD 60 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Got job 10 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 12 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/12/18 18:27:55 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[60] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 60,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 60,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[60] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 59}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 59,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[59] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 58}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 58,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[58] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.8 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[60] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 11.0 (TID 18)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 11.0 (TID 18). 2705 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 18) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ShuffleMapStage 11 (count at LinearRegression.scala:696) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:55 INFO DAGScheduler: running: Set()
17/12/18 18:27:55 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/12/18 18:27:55 INFO DAGScheduler: failed: Set()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[63] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 63,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 63,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[63] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 62}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 62,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[62] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 61}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 61,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[61] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 60}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[63] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 19, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 12.0 (TID 19)
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 12.0 (TID 19). 1581 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 12 (count at LinearRegression.scala:696) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: Job 10 finished: count at LinearRegression.scala:696, took 0.024135 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-836570670-3: training finished
17/12/18 18:27:55 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:55 INFO DAGScheduler: Got job 11 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 13 (first at LinearRegression.scala:198)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[65] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 13,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 13,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 65,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 65,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[65] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 64}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 64,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[64] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 28.9 KB, free 364.7 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.7 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[65] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 13.0 (TID 20)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: 1 block locks were not released by TID = 20:
[rdd_12_0]
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 13.0 (TID 20). 2367 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 20) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 13 (first at LinearRegression.scala:198) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: Job 11 finished: first at LinearRegression.scala:198, took 0.014285 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-861264314-4: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-861264314-4: {"elasticNetParam":0.5,"fitIntercept":true,"maxIter":10,"regParam":0.1}
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-861264314-4: {"numFeatures":10}
17/12/18 18:27:55 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:55 INFO DAGScheduler: Got job 12 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[74] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 14,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 14,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 74,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 74,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[74] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 70}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 70,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[70] at map at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 69}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 69,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[69] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 68}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 68,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[68] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 67}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 67,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[67] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 66}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 66,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[66] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 39.0 KB, free 364.7 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.7 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[74] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 14.0 (TID 21)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 14.0 (TID 21). 3340 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 14 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.009 s
17/12/18 18:27:55 INFO DAGScheduler: Job 12 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.018239 s
17/12/18 18:27:55 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 361
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 197
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 353
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 359
17/12/18 18:27:55 INFO ContextCleaner: Cleaned shuffle 0
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 194
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 357
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 191
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 411
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 358
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 274
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 196
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 352
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 192
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 362
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 248
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 187
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 356
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 355
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 350
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 198
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 110
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 275
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 111
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 195
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 360
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 112
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 199
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 354
17/12/18 18:27:55 INFO ContextCleaner: Cleaned shuffle 1
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 188
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 190
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 351
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 193
17/12/18 18:27:55 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 273
17/12/18 18:27:55 INFO ContextCleaner: Cleaned accumulator 189
17/12/18 18:27:55 INFO OWLQN: Step Size: 0.2658
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.492816 (rel: 0.0144) 0.130264
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483938 (rel: 0.0180) 0.00511189
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483927 (rel: 2.37e-05) 0.00136333
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483926 (rel: 1.53e-06) 0.000210422
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483926 (rel: 4.96e-08) 2.76015e-05
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483926 (rel: 9.22e-10) 2.57189e-06
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483926 (rel: 8.52e-12) 5.20310e-07
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.483926 (rel: 2.78e-13) 1.37423e-07
17/12/18 18:27:55 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:55 INFO DAGScheduler: Got job 13 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 15 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[80] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 15,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 15,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 80,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 80,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[80] at map at RegressionMetrics.scala:55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 79}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 79,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[79] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 78}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 78,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[78] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 77}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 77,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[77] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 76}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 76,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[76] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 75}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 75,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[75] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 39.7 KB, free 365.2 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.1 KB, free 365.2 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[80] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 15.0 (TID 22)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 15.0 (TID 22). 2790 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 22) in 12 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 15 (aggregate at RegressionMetrics.scala:57) finished in 0.012 s
17/12/18 18:27:55 INFO DAGScheduler: Job 13 finished: aggregate at RegressionMetrics.scala:57, took 0.020188 s
17/12/18 18:27:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:55 INFO DAGScheduler: Got job 14 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 16 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[81] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 16,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 16,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 81,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 81,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[81] at map at RegressionMetrics.scala:69,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 79}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 79,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[79] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 78}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 78,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[78] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 77}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 77,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[77] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 76}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 76,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[76] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 75}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 75,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[75] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.3 KB, free 365.2 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.0 KB, free 365.1 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[81] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 23)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 23). 2307 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 23) in 8 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 16 (sum at RegressionMetrics.scala:71) finished in 0.009 s
17/12/18 18:27:55 INFO DAGScheduler: Job 14 finished: sum at RegressionMetrics.scala:71, took 0.015046 s
17/12/18 18:27:55 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:55 INFO DAGScheduler: Registering RDD 84 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Got job 15 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 18 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
17/12/18 18:27:55 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[84] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 17,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 17,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 84,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 84,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[84] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 83}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 83,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[83] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 82}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 82,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[82] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 32.8 KB, free 365.1 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 12.7 KB, free 365.1 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[84] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 24)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 17.0 (TID 24). 2705 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ShuffleMapStage 17 (count at LinearRegression.scala:696) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:55 INFO DAGScheduler: running: Set()
17/12/18 18:27:55 INFO DAGScheduler: waiting: Set(ResultStage 18)
17/12/18 18:27:55 INFO DAGScheduler: failed: Set()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[87] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 18,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 18,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 87,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 87,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[87] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 86}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 86,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[86] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 85}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 85,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[85] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 84}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.0 KB, free 365.1 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.1 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[87] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 25, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 18.0 (TID 25)
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 18.0 (TID 25). 1581 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 18 (count at LinearRegression.scala:696) finished in 0.005 s
17/12/18 18:27:55 INFO DAGScheduler: Job 15 finished: count at LinearRegression.scala:696, took 0.023454 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-861264314-4: training finished
17/12/18 18:27:55 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:55 INFO DAGScheduler: Got job 16 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 19 (first at LinearRegression.scala:198)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[89] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 19,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 19,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 89,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 89,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[89] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 88}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 88,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[88] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.9 KB, free 365.1 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 11.1 KB, free 365.0 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[89] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 19.0 (TID 26)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: 1 block locks were not released by TID = 26:
[rdd_12_0]
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 19.0 (TID 26). 2367 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 26) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 19 (first at LinearRegression.scala:198) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 16 finished: first at LinearRegression.scala:198, took 0.012698 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-1071714449-5: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-1071714449-5: {"elasticNetParam":0.5,"fitIntercept":true,"maxIter":10,"regParam":0.01}
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-1071714449-5: {"numFeatures":10}
17/12/18 18:27:55 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:55 INFO DAGScheduler: Got job 17 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[98] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 20,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 20,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 98,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 98,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[98] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 94}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 94,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[94] at map at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 93}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 93,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[93] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 92}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 92,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[92] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 91}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 91,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[91] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 90}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 90,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[90] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 39.0 KB, free 365.0 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 15.0 KB, free 365.0 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[98] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 20.0 (TID 27)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 27). 3297 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 20 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 17 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.013908 s
17/12/18 18:27:55 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:55 INFO OWLQN: Step Size: 0.2658
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.491919 (rel: 0.0162) 0.138610
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481696 (rel: 0.0208) 0.00611073
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481680 (rel: 3.45e-05) 0.00169383
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481679 (rel: 2.37e-06) 0.000248957
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481679 (rel: 6.92e-08) 3.39500e-05
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481679 (rel: 1.45e-09) 4.37295e-06
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481679 (rel: 2.36e-11) 1.00896e-06
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.481679 (rel: 9.08e-13) 1.97833e-07
17/12/18 18:27:55 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:55 INFO DAGScheduler: Got job 18 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 21 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[104] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 21,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 21,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 104,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 104,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[104] at map at RegressionMetrics.scala:55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 103}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 103,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[103] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 102}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 102,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[102] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 101}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 101,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[101] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 100}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 100,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[100] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 99}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 99,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[99] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 39.7 KB, free 364.9 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.9 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[104] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 21.0 (TID 28)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 21.0 (TID 28). 2833 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 28) in 8 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 21 (aggregate at RegressionMetrics.scala:57) finished in 0.009 s
17/12/18 18:27:55 INFO DAGScheduler: Job 18 finished: aggregate at RegressionMetrics.scala:57, took 0.015758 s
17/12/18 18:27:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:55 INFO DAGScheduler: Got job 19 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 22 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[105] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 22,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 22,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 105,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 105,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[105] at map at RegressionMetrics.scala:69,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 103}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 103,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[103] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 102}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 102,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[102] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 101}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 101,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[101] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 100}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 100,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[100] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 99}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 99,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[99] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 39.3 KB, free 364.9 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.9 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[105] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 22.0 (TID 29)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 22.0 (TID 29). 2307 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 29) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 22 (sum at RegressionMetrics.scala:71) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 19 finished: sum at RegressionMetrics.scala:71, took 0.013368 s
17/12/18 18:27:55 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:55 INFO DAGScheduler: Registering RDD 108 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Got job 20 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 24 (count at LinearRegression.scala:696)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
17/12/18 18:27:55 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[108] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 23,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 23,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 108,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 108,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[108] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 107}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 107,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[107] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 106}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[106] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 32.8 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[108] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 23.0 (TID 30)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 23.0 (TID 30). 2705 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 30) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ShuffleMapStage 23 (count at LinearRegression.scala:696) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:55 INFO DAGScheduler: running: Set()
17/12/18 18:27:55 INFO DAGScheduler: waiting: Set(ResultStage 24)
17/12/18 18:27:55 INFO DAGScheduler: failed: Set()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[111] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 24,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 24,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 111,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 111,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[111] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 110}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 110,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[110] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 109}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 109,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[109] at count at LinearRegression.scala:696,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 108}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[111] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 31, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 24.0 (TID 31)
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 24.0 (TID 31). 1538 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 31) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 24 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:55 INFO DAGScheduler: Job 20 finished: count at LinearRegression.scala:696, took 0.020064 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-1071714449-5: training finished
17/12/18 18:27:55 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:55 INFO DAGScheduler: Got job 21 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 25 (first at LinearRegression.scala:198)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[113] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 25,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 25,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 113,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 113,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[113] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 112}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 112,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[112] at first at LinearRegression.scala:198,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 28.9 KB, free 364.8 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.8 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[113] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 25.0 (TID 32)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: 1 block locks were not released by TID = 32:
[rdd_12_0]
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 25.0 (TID 32). 2367 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 25 (first at LinearRegression.scala:198) finished in 0.004 s
17/12/18 18:27:55 INFO DAGScheduler: Job 21 finished: first at LinearRegression.scala:198, took 0.009559 s
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-2140898588-6: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-2140898588-6: {"elasticNetParam":1.0,"fitIntercept":true,"maxIter":10,"regParam":0.1}
17/12/18 18:27:55 INFO Instrumentation: LinearRegression-linReg_be181b167431-2140898588-6: {"numFeatures":10}
17/12/18 18:27:55 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:55 INFO DAGScheduler: Got job 22 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[122] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 26,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 26,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 122,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 122,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[122] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 118}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 118,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[118] at map at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 117}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 117,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[117] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 116}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 116,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[116] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 115}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 115,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[115] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 114}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 114,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[114] at rdd at LinearRegression.scala:202,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 39.0 KB, free 364.7 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.7 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[122] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 26.0 (TID 33)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 26.0 (TID 33). 3297 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 33) in 7 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 26 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 22 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.014815 s
17/12/18 18:27:55 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:55 INFO OWLQN: Step Size: 0.2658
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.493715 (rel: 0.0126) 0.121838
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486072 (rel: 0.0155) 0.0106705
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486016 (rel: 0.000114) 0.00199191
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486014 (rel: 4.35e-06) 0.000486816
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486014 (rel: 3.04e-07) 7.77744e-05
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486014 (rel: 5.57e-09) 2.10609e-05
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486014 (rel: 3.62e-10) 2.21118e-06
17/12/18 18:27:55 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:55 INFO OWLQN: Val and Grad Norm: 0.486014 (rel: 5.70e-12) 4.75851e-07
17/12/18 18:27:55 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:55 INFO DAGScheduler: Got job 23 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 27 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[128] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 27,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 27,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 128,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 128,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[128] at map at RegressionMetrics.scala:55,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 127}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 127,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[127] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 126}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 126,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[126] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 125}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 125,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[125] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 124}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 124,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[124] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 123}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 123,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[123] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 39.7 KB, free 364.7 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.7 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[128] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 27.0 (TID 34)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 27.0 (TID 34). 2790 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 34) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 27 (aggregate at RegressionMetrics.scala:57) finished in 0.006 s
17/12/18 18:27:55 INFO DAGScheduler: Job 23 finished: aggregate at RegressionMetrics.scala:57, took 0.012890 s
17/12/18 18:27:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:55 INFO DAGScheduler: Got job 24 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:55 INFO DAGScheduler: Final stage: ResultStage 28 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:55 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:55 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:55 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[129] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   id: 28,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 28,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 129,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 129,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[129] at map at RegressionMetrics.scala:69,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 127}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 127,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[127] at map at LinearRegression.scala:632,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 126}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 126,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[126] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 125}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 125,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[125] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 124}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 124,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[124] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 123}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 123,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[123] at rdd at LinearRegression.scala:631,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:55 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 39.3 KB, free 364.6 MB)
17/12/18 18:27:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.6 MB)
17/12/18 18:27:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.0 MB)
17/12/18 18:27:55 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[129] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:55 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/12/18 18:27:55 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:55 INFO Executor: Running task 0.0 in stage 28.0 (TID 35)
17/12/18 18:27:55 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:55 INFO Executor: Finished task 0.0 in stage 28.0 (TID 35). 2307 bytes result sent to driver
17/12/18 18:27:55 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 35) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:55 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/12/18 18:27:55 INFO DAGScheduler: ResultStage 28 (sum at RegressionMetrics.scala:71) finished in 0.007 s
17/12/18 18:27:55 INFO DAGScheduler: Job 24 finished: sum at RegressionMetrics.scala:71, took 0.013477 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 132 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 25 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 30 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[132] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 29,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 29,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 132,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 132,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[132] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 131}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 131,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[131] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 130}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 130,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[130] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 32.8 KB, free 364.6 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.6 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[132] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 29.0 (TID 36)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 29.0 (TID 36). 2705 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 36) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 29 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 30)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[135] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 30,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 30,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 135,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 135,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[135] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 134}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 134,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[134] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 133}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 133,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[133] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 132}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.0 KB, free 364.6 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.6 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[135] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 37, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 30.0 (TID 37)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 30.0 (TID 37). 1538 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 37) in 2 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 30 (count at LinearRegression.scala:696) finished in 0.002 s
17/12/18 18:27:56 INFO DAGScheduler: Job 25 finished: count at LinearRegression.scala:696, took 0.016148 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-2140898588-6: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 26 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 31 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[137] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 31,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 31,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 137,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 137,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[137] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 136}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 136,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[136] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 28.9 KB, free 364.5 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.5 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[137] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 31.0 (TID 38)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 38:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 31.0 (TID 38). 2367 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 38) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 31 (first at LinearRegression.scala:198) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: Job 26 finished: first at LinearRegression.scala:198, took 0.009276 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-2104940330-7: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-2104940330-7: {"elasticNetParam":1.0,"fitIntercept":true,"maxIter":10,"regParam":0.01}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-2104940330-7: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 27 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[146] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 32,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 32,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 146,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 146,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[146] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 142}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 142,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[142] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 141}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 141,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[141] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 140}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 140,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[140] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 139}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 139,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[139] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 138}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 138,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[138] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 39.0 KB, free 364.5 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.5 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[146] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 32.0 (TID 39)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 32.0 (TID 39). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 39) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 32 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.007 s
17/12/18 18:27:56 INFO DAGScheduler: Job 27 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.013921 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO OWLQN: Step Size: 0.2658
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.492021 (rel: 0.0160) 0.137711
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481939 (rel: 0.0205) 0.00600939
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481923 (rel: 3.33e-05) 0.00166082
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481921 (rel: 2.28e-06) 0.000245517
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481921 (rel: 6.74e-08) 3.32999e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481921 (rel: 1.39e-09) 4.33115e-06
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481921 (rel: 2.51e-11) 6.74612e-07
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.481921 (rel: 4.19e-13) 2.49961e-07
17/12/18 18:27:56 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 28 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 33 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[152] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 33,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 33,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 152,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 152,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[152] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 151}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 151,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[151] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 150}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 150,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[150] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 149}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 149,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[149] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 148}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 148,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[148] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 147}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 147,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[147] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 39.7 KB, free 364.4 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.4 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[152] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 33.0 (TID 40)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 33.0 (TID 40). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 33 (aggregate at RegressionMetrics.scala:57) finished in 0.006 s
17/12/18 18:27:56 INFO DAGScheduler: Job 28 finished: aggregate at RegressionMetrics.scala:57, took 0.015107 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 29 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 34 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[153] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 34,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 34,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 153,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 153,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[153] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 151}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 151,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[151] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 150}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 150,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[150] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 149}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 149,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[149] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 148}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 148,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[148] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 147}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 147,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[147] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 39.3 KB, free 364.4 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.4 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[153] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 34.0 (TID 41)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 34.0 (TID 41). 2307 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 41) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 34 (sum at RegressionMetrics.scala:71) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 29 finished: sum at RegressionMetrics.scala:71, took 0.010960 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 156 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 30 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 36 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[156] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 35,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 35,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 156,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 156,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[156] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 155}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 155,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[155] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 154}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 154,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[154] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 32.8 KB, free 364.3 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.3 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[156] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 35.0 (TID 42)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 35.0 (TID 42). 2705 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 42) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 35 (count at LinearRegression.scala:696) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 36)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[159] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 36,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 36,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 159,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 159,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[159] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 158}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 158,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[158] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 157}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 157,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[157] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 156}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.0 KB, free 364.3 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.3 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[159] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 43, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 36.0 (TID 43)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 36.0 (TID 43). 1538 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 43) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 36 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 30 finished: count at LinearRegression.scala:696, took 0.019242 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-2104940330-7: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 31 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 37 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[161] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 37,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 37,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 161,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 161,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[161] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 160}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 160,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[160] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 28.9 KB, free 364.3 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.3 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[161] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 37.0 (TID 44)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 44:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 37.0 (TID 44). 2367 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 37 (first at LinearRegression.scala:198) finished in 0.006 s
17/12/18 18:27:56 INFO DAGScheduler: Job 31 finished: first at LinearRegression.scala:198, took 0.018273 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-966446307-8: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-966446307-8: {"elasticNetParam":0.0,"fitIntercept":false,"maxIter":10,"regParam":0.1}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-966446307-8: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 32 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[170] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 38,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 38,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 170,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 170,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[170] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 166}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 166,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[166] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 165}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 165,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[165] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 164}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 164,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[164] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 163}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 163,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[163] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 162}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 162,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[162] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 39.0 KB, free 364.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.2 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[170] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 38.0 (TID 45)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 38.0 (TID 45). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 45) in 7 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 38 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.007 s
17/12/18 18:27:56 INFO DAGScheduler: Job 32 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.013883 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 33 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 39 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[176] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 39,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 39,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 176,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 176,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[176] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 175}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 175,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[175] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 174}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 174,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[174] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 173}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 173,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[173] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 172}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 172,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[172] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 171}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 171,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[171] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 39.7 KB, free 364.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.2 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[176] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 39.0 (TID 46)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 39.0 (TID 46). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 46) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 39 (aggregate at RegressionMetrics.scala:57) finished in 0.006 s
17/12/18 18:27:56 INFO DAGScheduler: Job 33 finished: aggregate at RegressionMetrics.scala:57, took 0.012281 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 34 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 40 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[177] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 40,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 40,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 177,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 177,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[177] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 175}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 175,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[175] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 174}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 174,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[174] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 173}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 173,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[173] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 172}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 172,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[172] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 171}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 171,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[171] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 39.3 KB, free 364.1 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[177] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 40.0 (TID 47)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 40.0 (TID 47). 2350 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 47) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 40 (sum at RegressionMetrics.scala:71) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: Job 34 finished: sum at RegressionMetrics.scala:71, took 0.011460 s
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 685
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 521
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1007
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 927
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 925
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 844
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 686
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 574
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1011
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1012
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 848
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 519
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 839
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 677
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 900
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1009
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 599
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1010
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 676
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 737
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 684
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 840
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 681
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 847
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 843
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 525
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1006
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 842
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 763
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 520
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1008
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 764
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 517
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 762
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1165
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 851
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 514
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 518
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 438
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 513
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 180 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 35 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 42 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[180] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 41,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 41,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 180,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 180,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[180] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 179}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 179,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[179] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 178}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 178,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[178] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 32.8 KB, free 364.7 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.7 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 524
17/12/18 18:27:56 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[180] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 41.0 (TID 48)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 5
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1013
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 926
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 41.0 (TID 48). 2705 bytes result sent to driver
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 48) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 41 (count at LinearRegression.scala:696) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 42)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 515
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 845
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[183] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 850
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 601
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 42,
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 687
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 42,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 183,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 183,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[183] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 182}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 182,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[182] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 181}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 181,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[181] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 180}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1014
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1002
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 680
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.0 KB, free 364.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1003
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 849
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 522
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1004
17/12/18 18:27:56 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[183] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 49, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 3
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 523
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 42.0 (TID 49)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 846
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 42.0 (TID 49). 1581 bytes result sent to driver
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1063
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 688
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 4
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 436
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 49) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 42 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 35 finished: count at LinearRegression.scala:696, took 0.017784 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-966446307-8: training finished
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 2
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 683
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 841
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 516
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 678
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 600
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 682
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 679
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1005
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 437
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 36 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 43 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[185] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 43,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 43,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 185,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 185,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[185] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 184}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 184,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[184] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 28.9 KB, free 365.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 11.1 KB, free 365.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[185] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 43.0 (TID 50)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 50:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 43.0 (TID 50). 2367 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 50) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 43 (first at LinearRegression.scala:198) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 36 finished: first at LinearRegression.scala:198, took 0.008419 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-399662621-9: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-399662621-9: {"elasticNetParam":0.0,"fitIntercept":false,"maxIter":10,"regParam":0.01}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-399662621-9: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 37 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[194] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 44,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 44,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 194,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 194,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[194] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 190}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 190,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[190] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 189}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 189,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[189] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 188}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 188,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[188] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 187}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 187,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[187] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 186}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 186,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[186] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 39.0 KB, free 365.1 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 15.0 KB, free 365.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[194] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 44.0 (TID 51)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 44.0 (TID 51). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 51) in 6 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 44 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: Job 37 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.012106 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 38 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 45 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[200] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 45,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 45,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 200,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 200,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[200] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 199}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 199,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[199] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 198}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[198] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 197}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 197,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[197] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 196}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 196,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[196] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 195}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 195,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[195] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 39.7 KB, free 365.1 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 16.1 KB, free 365.0 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[200] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 45.0 (TID 52)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 45.0 (TID 52). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 52) in 13 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 45 (aggregate at RegressionMetrics.scala:57) finished in 0.013 s
17/12/18 18:27:56 INFO DAGScheduler: Job 38 finished: aggregate at RegressionMetrics.scala:57, took 0.021967 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 39 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 46 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[201] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 46,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 46,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 201,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 201,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[201] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 199}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 199,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[199] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 198}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[198] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 197}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 197,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[197] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 196}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 196,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[196] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 195}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 195,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[195] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 39.3 KB, free 365.0 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.0 KB, free 365.0 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[201] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 46.0 (TID 53)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 46.0 (TID 53). 2307 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 46 (sum at RegressionMetrics.scala:71) finished in 0.011 s
17/12/18 18:27:56 INFO DAGScheduler: Job 39 finished: sum at RegressionMetrics.scala:71, took 0.017759 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 204 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 40 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 48 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[204] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 47,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 47,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 204,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 204,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[204] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 203}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 203,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[203] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 202}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[202] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 32.8 KB, free 365.0 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[204] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 47.0 (TID 54)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 47.0 (TID 54). 2662 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 54) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 47 (count at LinearRegression.scala:696) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 48)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[207] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 48,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 48,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 207,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 207,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[207] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 206}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 206,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[206] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 205}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 205,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[205] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 204}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.0 KB, free 364.9 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[207] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 55, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 48.0 (TID 55)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 48.0 (TID 55). 1581 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 55) in 2 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 48 (count at LinearRegression.scala:696) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 40 finished: count at LinearRegression.scala:696, took 0.017430 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-399662621-9: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 41 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 49 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[209] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 49,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 49,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 209,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 209,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[209] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 208}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 208,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[208] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 28.9 KB, free 364.9 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.9 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[209] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 49.0 (TID 56)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 56:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 49.0 (TID 56). 2324 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 56) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 49 (first at LinearRegression.scala:198) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 41 finished: first at LinearRegression.scala:198, took 0.006775 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-631181275-10: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-631181275-10: {"elasticNetParam":0.5,"fitIntercept":false,"maxIter":10,"regParam":0.1}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-631181275-10: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 42 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[218] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 50,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 50,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 218,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 218,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[218] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 214}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 214,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[214] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 213}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 213,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[213] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 212}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 212,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[212] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 211}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 211,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[211] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 210}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 210,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[210] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 39.0 KB, free 364.9 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.8 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[218] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 50.0 (TID 57)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 50.0 (TID 57). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 50 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 42 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.009929 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO OWLQN: Step Size: 0.2684
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.493275 (rel: 0.0141) 0.128145
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484849 (rel: 0.0171) 0.0144519
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484747 (rel: 0.000212) 0.00276524
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484743 (rel: 8.43e-06) 0.000603787
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484742 (rel: 4.64e-07) 9.62059e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484742 (rel: 8.51e-09) 2.51515e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484742 (rel: 5.54e-10) 2.69244e-06
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.484742 (rel: 8.43e-12) 4.36916e-07
17/12/18 18:27:56 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 43 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 51 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[224] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 51,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 51,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 224,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 224,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[224] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 223}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 223,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[223] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 222}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 222,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[222] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 221}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 221,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[221] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 220}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 220,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[220] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 219}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 219,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[219] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 39.7 KB, free 364.8 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.8 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[224] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 51.0 (TID 58)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 51.0 (TID 58). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 58) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 51 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 43 finished: aggregate at RegressionMetrics.scala:57, took 0.011611 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 44 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 52 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[225] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 52,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 52,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 225,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 225,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[225] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 223}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 223,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[223] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 222}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 222,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[222] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 221}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 221,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[221] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 220}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 220,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[220] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 219}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 219,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[219] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 39.3 KB, free 364.7 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.7 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[225] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 52.0 (TID 59)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 52.0 (TID 59). 2307 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 59) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 52 (sum at RegressionMetrics.scala:71) finished in 0.007 s
17/12/18 18:27:56 INFO DAGScheduler: Job 44 finished: sum at RegressionMetrics.scala:71, took 0.012942 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 228 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 45 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 54 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[228] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 53,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 53,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 228,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 228,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[228] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 227}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 227,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[227] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 226}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 226,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[226] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 32.8 KB, free 364.7 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.7 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[228] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 53.0 (TID 60)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 53.0 (TID 60). 2662 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 60) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 53 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 54)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[231] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 54,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 54,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 231,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 231,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[231] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 230}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 230,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[230] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 229}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 229,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[229] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 228}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 7.0 KB, free 364.7 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.7 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[231] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 61, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 54.0 (TID 61)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 54.0 (TID 61). 1538 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 61) in 2 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 54 (count at LinearRegression.scala:696) finished in 0.002 s
17/12/18 18:27:56 INFO DAGScheduler: Job 45 finished: count at LinearRegression.scala:696, took 0.014651 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-631181275-10: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 46 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 55 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[233] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 233,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 233,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[233] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 232}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 232,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[232] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 28.9 KB, free 364.6 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.6 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[233] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 55.0 (TID 62)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 62:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 55.0 (TID 62). 2324 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 62) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 55 (first at LinearRegression.scala:198) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 46 finished: first at LinearRegression.scala:198, took 0.007547 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-470870842-11: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-470870842-11: {"elasticNetParam":0.5,"fitIntercept":false,"maxIter":10,"regParam":0.01}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-470870842-11: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 47 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[242] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 56,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 56,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 242,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 242,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[242] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 238}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 238,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[238] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 237}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 237,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[237] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 236}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 236,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[236] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 235}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 235,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[235] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 234}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 234,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[234] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 39.0 KB, free 364.6 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.6 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[242] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 56.0 (TID 63)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 56.0 (TID 63). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 56 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 47 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.008416 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO OWLQN: Step Size: 0.2684
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.492371 (rel: 0.0160) 0.136503
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482726 (rel: 0.0196) 0.0201167
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482526 (rel: 0.000414) 0.00393786
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482518 (rel: 1.71e-05) 0.000827385
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482517 (rel: 8.87e-07) 0.000126595
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482517 (rel: 1.53e-08) 3.35418e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482517 (rel: 9.85e-10) 3.13483e-06
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482517 (rel: 1.12e-11) 4.44967e-07
17/12/18 18:27:56 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 48 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 57 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[248] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 57,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 57,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 248,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 248,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[248] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 247}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 247,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[247] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 246}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 246,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[246] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 245}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 245,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[245] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 244}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 244,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[244] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 243}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 243,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[243] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 39.7 KB, free 364.5 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.5 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[248] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 57.0 (TID 64)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 57.0 (TID 64). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 64) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 57 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 48 finished: aggregate at RegressionMetrics.scala:57, took 0.009715 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 49 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 58 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[249] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 58,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 58,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 249,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 249,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[249] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 247}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 247,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[247] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 246}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 246,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[246] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 245}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 245,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[245] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 244}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 244,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[244] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 243}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 243,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[243] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 39.3 KB, free 364.5 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.5 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[249] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 58.0 (TID 65)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 58.0 (TID 65). 2307 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 65) in 5 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 58 (sum at RegressionMetrics.scala:71) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: Job 49 finished: sum at RegressionMetrics.scala:71, took 0.012998 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 252 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 50 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 60 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[252] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 59,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 59,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 252,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 252,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[252] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 251}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 251,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[251] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 250}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 250,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[250] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 32.8 KB, free 364.4 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.4 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[252] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 59.0 (TID 66)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 59.0 (TID 66). 2705 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 66) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 59 (count at LinearRegression.scala:696) finished in 0.005 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 60)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[255] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 60,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 60,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 255,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 255,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[255] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 254}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 254,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[254] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 253}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 253,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[253] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 252}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[255] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 67, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 60.0 (TID 67)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 60.0 (TID 67). 1581 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 67) in 2 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 60 (count at LinearRegression.scala:696) finished in 0.002 s
17/12/18 18:27:56 INFO DAGScheduler: Job 50 finished: count at LinearRegression.scala:696, took 0.015905 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-470870842-11: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 51 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 61 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[257] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 61,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 61,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 257,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 257,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[257] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 256}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 256,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[256] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 28.9 KB, free 364.4 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.4 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[257] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 61.0 (TID 68)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 68:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 61.0 (TID 68). 2367 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 68) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 61 (first at LinearRegression.scala:198) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 51 finished: first at LinearRegression.scala:198, took 0.006392 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-1823595027-12: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-1823595027-12: {"elasticNetParam":1.0,"fitIntercept":false,"maxIter":10,"regParam":0.1}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-1823595027-12: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 52 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[266] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 62,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 62,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 266,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 266,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[266] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 262}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 262,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[262] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 261}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 261,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[261] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 260}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 260,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[260] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 259}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 259,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[259] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 258}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 258,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[258] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 39.0 KB, free 364.3 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.3 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[266] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 62.0 (TID 69)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 62.0 (TID 69). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 69) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 62 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 52 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.009312 s
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO OWLQN: Step Size: 0.2684
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.494179 (rel: 0.0123) 0.119635
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486854 (rel: 0.0148) 0.00907900
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486813 (rel: 8.47e-05) 0.00150546
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486812 (rel: 2.56e-06) 0.000218120
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486812 (rel: 5.24e-08) 4.40557e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486812 (rel: 1.75e-09) 4.66351e-06
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486812 (rel: 2.23e-11) 1.12771e-06
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.486812 (rel: 1.73e-12) 7.97653e-08
17/12/18 18:27:56 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:56 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:56 INFO DAGScheduler: Got job 53 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 63 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[272] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 63,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 63,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 272,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 272,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[272] at map at RegressionMetrics.scala:55,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 271}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 271,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[271] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 270}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 270,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[270] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 269}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 269,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[269] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 268}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 268,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[268] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 267}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 267,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[267] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 39.7 KB, free 364.3 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 16.1 KB, free 364.3 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[272] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 63.0 (TID 70)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 63.0 (TID 70). 2790 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 70) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 63 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 53 finished: aggregate at RegressionMetrics.scala:57, took 0.008401 s
17/12/18 18:27:56 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:56 INFO DAGScheduler: Got job 54 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 64 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[273] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 64,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 64,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 273,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 273,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[273] at map at RegressionMetrics.scala:69,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 271}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 271,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[271] at map at LinearRegression.scala:632,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 270}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 270,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[270] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 269}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 269,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[269] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 268}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 268,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[268] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 267}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 267,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[267] at rdd at LinearRegression.scala:631,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 39.3 KB, free 364.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.0 KB, free 364.2 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[273] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 64.0 (TID 71)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 64.0 (TID 71). 2307 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 71) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 64 (sum at RegressionMetrics.scala:71) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 54 finished: sum at RegressionMetrics.scala:71, took 0.007756 s
17/12/18 18:27:56 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:56 INFO DAGScheduler: Registering RDD 276 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Got job 55 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 66 (count at LinearRegression.scala:696)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
17/12/18 18:27:56 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[276] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 65,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 65,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 276,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 276,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[276] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 275}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 275,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[275] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 274}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 274,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[274] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 32.8 KB, free 364.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 12.7 KB, free 364.2 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[276] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 65.0 (TID 72)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 65.0 (TID 72). 2705 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 72) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ShuffleMapStage 65 (count at LinearRegression.scala:696) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:56 INFO DAGScheduler: running: Set()
17/12/18 18:27:56 INFO DAGScheduler: waiting: Set(ResultStage 66)
17/12/18 18:27:56 INFO DAGScheduler: failed: Set()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[279] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 66,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 66,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 279,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 279,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[279] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 278}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 278,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[278] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 277}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 277,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[277] at count at LinearRegression.scala:696,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 276}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 7.0 KB, free 364.2 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.2 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[279] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 73, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 66.0 (TID 73)
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 66.0 (TID 73). 1538 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 73) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 66 (count at LinearRegression.scala:696) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 55 finished: count at LinearRegression.scala:696, took 0.012449 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-1823595027-12: training finished
17/12/18 18:27:56 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:56 INFO DAGScheduler: Got job 56 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 67 (first at LinearRegression.scala:198)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[281] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 67,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 67,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 281,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 281,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[281] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 280}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 280,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[280] at first at LinearRegression.scala:198,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 28.9 KB, free 364.1 MB)
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 11.1 KB, free 364.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 138.96.200.169:36769 (size: 11.1 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[281] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 67.0 (TID 74)
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO Executor: 1 block locks were not released by TID = 74:
[rdd_12_0]
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 67.0 (TID 74). 2324 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 74) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 67 (first at LinearRegression.scala:198) finished in 0.003 s
17/12/18 18:27:56 INFO DAGScheduler: Job 56 finished: first at LinearRegression.scala:198, took 0.006138 s
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-657986711-13: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-657986711-13: {"elasticNetParam":1.0,"fitIntercept":false,"maxIter":10,"regParam":0.01}
17/12/18 18:27:56 INFO Instrumentation: LinearRegression-linReg_be181b167431-657986711-13: {"numFeatures":10}
17/12/18 18:27:56 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:56 INFO DAGScheduler: Got job 57 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:56 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:56 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:56 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:56 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[290] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   id: 68,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 68,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 290,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 290,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[290] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 286}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 286,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[286] at map at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 285}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 285,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[285] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 284}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 284,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[284] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 283}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 283,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[283] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 282}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 282,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[282] at rdd at LinearRegression.scala:202,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:56 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 39.0 KB, free 364.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1655
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1660
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1176
17/12/18 18:27:56 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 15.0 KB, free 364.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 8
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1170
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1817
17/12/18 18:27:56 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 138.96.200.169:36769 (size: 15.0 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[290] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:56 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:56 INFO Executor: Running task 0.0 in stage 68.0 (TID 75)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1499
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.8 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1502
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1253
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1167
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1824
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1340
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1666
17/12/18 18:27:56 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1503
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1663
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1579
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1497
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1659
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1177
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1822
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1654
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1337
17/12/18 18:27:56 INFO Executor: Finished task 0.0 in stage 68.0 (TID 75). 3297 bytes result sent to driver
17/12/18 18:27:56 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 75) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
17/12/18 18:27:56 INFO DAGScheduler: ResultStage 68 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.004 s
17/12/18 18:27:56 INFO DAGScheduler: Job 57 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.014363 s
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO WeightedLeastSquares: Number of instances: 354.
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1742
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 365.9 MB)
17/12/18 18:27:56 INFO OWLQN: Step Size: 0.2684
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.492474 (rel: 0.0157) 0.135643
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1493
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1416
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1495
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1252
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1494
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 9
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1664
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1174
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482954 (rel: 0.0193) 0.0195423
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1332
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482766 (rel: 0.000390) 0.00375029
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1496
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1662
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1089
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1740
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482758 (rel: 1.55e-05) 0.000788570
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482758 (rel: 8.06e-07) 0.000121580
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1665
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1331
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482758 (rel: 1.40e-08) 3.23696e-05
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482758 (rel: 9.17e-10) 3.10665e-06
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:56 INFO OWLQN: Val and Grad Norm: 0.482758 (rel: 1.11e-11) 4.54346e-07
17/12/18 18:27:56 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1741
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1090
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1335
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1415
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1251
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1329
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1657
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1414
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 6
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 7
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.0 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1172
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1658
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1166
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1577
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1878
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1389
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1715
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1171
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1819
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1826
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1825
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1829
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1338
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1491
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1226
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1173
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1168
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1820
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1492
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1828
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1823
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1333
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1501
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1500
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1661
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1821
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1330
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1818
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1498
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1827
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1339
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1334
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1656
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1328
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1088
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1552
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1175
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1578
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1336
17/12/18 18:27:56 INFO ContextCleaner: Cleaned accumulator 1169
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 138.96.200.169:36769 in memory (size: 11.1 KB, free: 366.1 MB)
17/12/18 18:27:56 INFO ContextCleaner: Cleaned shuffle 10
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 58 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 69 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[296] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 69,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 69,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 296,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 296,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[296] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 295}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 295,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[295] at map at LinearRegression.scala:632,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 294}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 294,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[294] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 293}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 293,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[293] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 292}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 292,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[292] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 291}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 291,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[291] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 39.7 KB, free 365.2 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 16.1 KB, free 365.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 138.96.200.169:36769 (size: 16.1 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[296] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 69.0 (TID 76)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 69.0 (TID 76). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 76) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 69 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 58 finished: aggregate at RegressionMetrics.scala:57, took 0.007632 s
17/12/18 18:27:57 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:57 INFO DAGScheduler: Got job 59 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 70 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[297] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 70,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 70,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 297,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 297,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[297] at map at RegressionMetrics.scala:69,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 295}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 295,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[295] at map at LinearRegression.scala:632,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 294}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 294,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[294] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 293}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 293,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[293] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 292}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 292,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[292] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 291}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 291,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[291] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 39.3 KB, free 365.1 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 16.0 KB, free 365.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 138.96.200.169:36769 (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[297] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 70.0 (TID 77)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 70.0 (TID 77). 2307 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 77) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 70 (sum at RegressionMetrics.scala:71) finished in 0.005 s
17/12/18 18:27:57 INFO DAGScheduler: Job 59 finished: sum at RegressionMetrics.scala:71, took 0.008740 s
17/12/18 18:27:57 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:57 INFO DAGScheduler: Registering RDD 300 (count at LinearRegression.scala:696)
17/12/18 18:27:57 INFO DAGScheduler: Got job 60 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 72 (count at LinearRegression.scala:696)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
17/12/18 18:27:57 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[300] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 71,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 71,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 300,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 300,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[300] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 299}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 299,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[299] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 298}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 298,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[298] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 12}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 12,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.0, 0.8, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[12] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 11}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 11,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[11] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 10}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 10,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[10] at cache at TrainValidationSplit.scala:106,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 32.8 KB, free 365.1 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 12.7 KB, free 365.0 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 138.96.200.169:36769 (size: 12.7 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[300] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 71.0 (TID 78)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_12_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 71.0 (TID 78). 2705 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 78) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ShuffleMapStage 71 (count at LinearRegression.scala:696) finished in 0.000 s
17/12/18 18:27:57 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:57 INFO DAGScheduler: running: Set()
17/12/18 18:27:57 INFO DAGScheduler: waiting: Set(ResultStage 72)
17/12/18 18:27:57 INFO DAGScheduler: failed: Set()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[303] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 72,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 72,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 303,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 303,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[303] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 302}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 302,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[302] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 301}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 301,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[301] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 300}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 7.0 KB, free 365.0 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.0 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[303] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 79, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 72.0 (TID 79)
17/12/18 18:27:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 72.0 (TID 79). 1581 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 79) in 2 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 72 (count at LinearRegression.scala:696) finished in 0.002 s
17/12/18 18:27:57 INFO DAGScheduler: Job 60 finished: count at LinearRegression.scala:696, took 0.014764 s
17/12/18 18:27:57 INFO Instrumentation: LinearRegression-linReg_be181b167431-657986711-13: training finished
17/12/18 18:27:57 INFO MapPartitionsRDD: Removing RDD 12 from persistence list
17/12/18 18:27:57 INFO BlockManager: Removing RDD 12
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 61 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 73 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[309] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 73,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 73,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 309,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 309,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[309] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 308}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 308,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[308] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 307}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 307,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[307] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 306}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 306,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[306] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 305}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 305,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[305] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 304}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 304,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[304] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 41.5 KB, free 365.1 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 17.0 KB, free 365.0 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[309] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 73.0 (TID 80)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 18.8 KB, free 365.0 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added rdd_15_0 in memory on 138.96.200.169:36769 (size: 18.8 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 73.0 (TID 80). 3514 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 80) in 45 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 73 (aggregate at RegressionMetrics.scala:57) finished in 0.045 s
17/12/18 18:27:57 INFO DAGScheduler: Job 61 finished: aggregate at RegressionMetrics.scala:57, took 0.050825 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 62 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 74 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[315] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 74,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 74,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 315,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 315,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[315] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 314}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 314,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[314] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 313}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 313,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[313] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 312}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 312,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[312] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 311}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 311,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[311] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 310}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 310,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[310] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 41.5 KB, free 365.0 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 17.1 KB, free 365.0 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 138.96.200.169:36769 (size: 17.1 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[315] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 74.0 (TID 81)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 74.0 (TID 81). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 81) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 74 (aggregate at RegressionMetrics.scala:57) finished in 0.003 s
17/12/18 18:27:57 INFO DAGScheduler: Job 62 finished: aggregate at RegressionMetrics.scala:57, took 0.009603 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 63 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 75 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[321] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 75,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 75,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 321,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 321,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[321] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 320}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 320,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[320] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 319}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 319,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[319] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 318}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 318,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[318] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 317}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 317,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[317] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 316}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 316,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[316] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 41.5 KB, free 364.9 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.9 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[321] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 75.0 (TID 82)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 75.0 (TID 82). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 82) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 75 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 63 finished: aggregate at RegressionMetrics.scala:57, took 0.007866 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 64 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 76 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[327] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 76,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 76,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 327,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 327,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[327] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 326}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 326,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[326] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 325}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 325,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[325] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 324}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 324,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[324] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 323}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 323,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[323] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 322}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 322,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[322] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 41.5 KB, free 364.9 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 17.1 KB, free 364.8 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 138.96.200.169:36769 (size: 17.1 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[327] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 76.0 (TID 83)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 76.0 (TID 83). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 83) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 76 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 64 finished: aggregate at RegressionMetrics.scala:57, took 0.009821 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 65 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 77 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[333] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 77,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 77,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 333,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 333,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[333] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 332}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 332,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[332] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 331}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 331,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[331] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 330}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 330,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[330] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 329}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 329,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[329] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 328}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 328,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[328] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.8 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[333] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 77.0 (TID 84)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 77.0 (TID 84). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 84) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 77 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 65 finished: aggregate at RegressionMetrics.scala:57, took 0.008622 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 66 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 78 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[339] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 78,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 78,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 339,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 339,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[339] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 338}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 338,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[338] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 337}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 337,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[337] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 336}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 336,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[336] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 335}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 335,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[335] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 334}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 334,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[334] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 41.5 KB, free 364.8 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.7 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[339] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 78.0 (TID 85)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 78.0 (TID 85). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 85) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 78 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 66 finished: aggregate at RegressionMetrics.scala:57, took 0.007562 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 67 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 79 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[345] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 79,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 79,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 345,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 345,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[345] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 344}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 344,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[344] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 343}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 343,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[343] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 342}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 342,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[342] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 341}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 341,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[341] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 340}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 340,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[340] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 41.5 KB, free 364.7 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 17.1 KB, free 364.7 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 138.96.200.169:36769 (size: 17.1 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[345] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 79.0 (TID 86)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 79.0 (TID 86). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 86) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 79 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 67 finished: aggregate at RegressionMetrics.scala:57, took 0.007320 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 68 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 80 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[351] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 80,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 80,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 351,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 351,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[351] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 350}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 350,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[350] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 349}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 349,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[349] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 348}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 348,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[348] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 347}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 347,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[347] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 346}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 346,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[346] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 41.5 KB, free 364.6 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 17.1 KB, free 364.6 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 138.96.200.169:36769 (size: 17.1 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[351] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 80.0 (TID 87)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 80.0 (TID 87). 2747 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 87) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 80 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 68 finished: aggregate at RegressionMetrics.scala:57, took 0.008088 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 69 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 81 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[357] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 81,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 81,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 357,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 357,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[357] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 356}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 356,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[356] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 355}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 355,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[355] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 354}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 354,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[354] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 353}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 353,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[353] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 352}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 352,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[352] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 41.5 KB, free 364.6 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.6 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[357] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 81.0 (TID 88)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 81.0 (TID 88). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 88) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 81 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 69 finished: aggregate at RegressionMetrics.scala:57, took 0.008371 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 70 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 82 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[363] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 363,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 363,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[363] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 362}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 362,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[362] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 361}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 361,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[361] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 360}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 360,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[360] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 359}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 359,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[359] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 358}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 358,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[358] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 41.5 KB, free 364.5 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.5 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[363] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 82.0 (TID 89)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 82.0 (TID 89). 2790 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 89) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 82 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 70 finished: aggregate at RegressionMetrics.scala:57, took 0.007360 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 71 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 83 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[369] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 369,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 369,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[369] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 368}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 368,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[368] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 367}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 367,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[367] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 366}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 366,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[366] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 365}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 365,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[365] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 364}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 364,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[364] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 41.5 KB, free 364.5 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.4 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[369] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 83.0 (TID 90)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 83.0 (TID 90). 2747 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 90) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 83 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 71 finished: aggregate at RegressionMetrics.scala:57, took 0.007281 s
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO DAGScheduler: Got job 72 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 84 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[375] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 84,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 84,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 375,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 375,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[375] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 374}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 374,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[374] at map at RegressionEvaluator.scala:83,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 373}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 373,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[373] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 372}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 372,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[372] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 371}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 371,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[371] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 370}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 370,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[370] at rdd at RegressionEvaluator.scala:82,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 15}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 15,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: *Sample 0.8, 1.0, false, -1772833110
+- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
   +- *Sample 0.0, 0.9, false, 12345
      +- *Sort [label#0 ASC NULLS FIRST, features#1 ASC NULLS FIRST], false, 0
         +- *FileScan libsvm [label#0,features#1] Batched: false, Format: LibSVM, Location: InMemoryFileIndex[file:/local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<label:double,features:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>
 MapPartitionsRDD[15] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(disk, memory, deserialized, 1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 14}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 14,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[14] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 13}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 13,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[13] at cache at TrainValidationSplit.scala:107,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 41.5 KB, free 364.4 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 17.0 KB, free 364.4 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 138.96.200.169:36769 (size: 17.0 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[375] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 84.0 (TID 91)
17/12/18 18:27:57 INFO BlockManager: Found block rdd_15_0 locally
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 84.0 (TID 91). 2747 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 91) in 4 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 84 (aggregate at RegressionMetrics.scala:57) finished in 0.004 s
17/12/18 18:27:57 INFO DAGScheduler: Job 72 finished: aggregate at RegressionMetrics.scala:57, took 0.007683 s
17/12/18 18:27:57 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
17/12/18 18:27:57 INFO BlockManager: Removing RDD 15
17/12/18 18:27:57 INFO TrainValidationSplit: Train validation split metrics: WrappedArray(9.718082906724453, 9.71911930429577, 9.70934190818752, 9.71805263652249, 9.704021125398512, 9.717019740168512, 9.657116520236238, 9.657891914333064, 9.649281664592866, 9.656915179540869, 9.644903128095804, 9.655973169171526)
17/12/18 18:27:57 INFO TrainValidationSplit: Best set of parameters:
{
	linReg_be181b167431-elasticNetParam: 1.0,
	linReg_be181b167431-fitIntercept: false,
	linReg_be181b167431-regParam: 0.1
}
17/12/18 18:27:57 INFO TrainValidationSplit: Best train validation split metric: 9.644903128095804.
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 15.577193 ms
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 308.6 KB, free 364.1 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 28.3 KB, free 364.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 89 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/12/18 18:27:57 INFO DAGScheduler: Got job 73 (first at LinearRegression.scala:198) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 85 (first at LinearRegression.scala:198)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[378] at first at LinearRegression.scala:198), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 85,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 85,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 378,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 378,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[378] at first at LinearRegression.scala:198,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 377}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 377,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[377] at first at LinearRegression.scala:198,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 376}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 376,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[376] at first at LinearRegression.scala:198,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 19.1 KB, free 364.1 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 8.3 KB, free 364.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 138.96.200.169:36769 (size: 8.3 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[378] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 85.0 (TID 92)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 85.0 (TID 92). 1967 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 92) in 17 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 85 (first at LinearRegression.scala:198) finished in 0.017 s
17/12/18 18:27:57 INFO DAGScheduler: Job 73 finished: first at LinearRegression.scala:198, took 0.021267 s
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 13.934565 ms
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 308.6 KB, free 363.8 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 28.3 KB, free 363.7 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 91 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 308.6 KB, free 363.4 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 28.3 KB, free 363.4 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 92 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO Instrumentation: LinearRegression-linReg_be181b167431-1276752040-14: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/12/18 18:27:57 INFO Instrumentation: LinearRegression-linReg_be181b167431-1276752040-14: {"elasticNetParam":1.0,"fitIntercept":false,"maxIter":10,"regParam":0.1}
17/12/18 18:27:57 INFO Instrumentation: LinearRegression-linReg_be181b167431-1276752040-14: {"numFeatures":10}
17/12/18 18:27:57 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/12/18 18:27:57 INFO DAGScheduler: Got job 74 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at WeightedLeastSquares.scala:100)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[388] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 86,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 86,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 388,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 388,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[388] at treeAggregate at WeightedLeastSquares.scala:100,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 383}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 383,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[383] at map at LinearRegression.scala:202,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 382}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 382,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[382] at rdd at LinearRegression.scala:202,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 381}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 381,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[381] at rdd at LinearRegression.scala:202,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 380}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 380,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[380] at rdd at LinearRegression.scala:202,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 379}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 379,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[379] at rdd at LinearRegression.scala:202,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 22.8 KB, free 363.4 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 9.8 KB, free 363.4 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 138.96.200.169:36769 (size: 9.8 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[388] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 86.0 (TID 93)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 86.0 (TID 93). 2807 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 93) in 25 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 86 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.025 s
17/12/18 18:27:57 INFO DAGScheduler: Job 74 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.029576 s
17/12/18 18:27:57 INFO WeightedLeastSquares: Number of instances: 447.
17/12/18 18:27:57 INFO OWLQN: Step Size: 0.2680
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.493724 (rel: 0.0126) 0.122290
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485756 (rel: 0.0161) 0.00264884
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 6.76e-06) 0.000637376
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 3.67e-07) 9.99843e-05
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 1.20e-08) 1.13449e-05
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 1.58e-10) 1.29177e-06
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 1.28e-12) 5.41575e-07
17/12/18 18:27:57 INFO OWLQN: Step Size: 1.000
17/12/18 18:27:57 INFO OWLQN: Val and Grad Norm: 0.485753 (rel: 2.40e-13) 1.50621e-08
17/12/18 18:27:57 INFO OWLQN: Converged because gradient converged
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 16.887998 ms
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 308.6 KB, free 363.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 138.96.200.169:36769 in memory (size: 12.7 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2224
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 77
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 74
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2145
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 138.96.200.169:36769 in memory (size: 16.1 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 80
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2146
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1985
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 83
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2357
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2301
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 138.96.200.169:36769 in memory (size: 9.8 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 28.3 KB, free 363.2 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 94 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 138.96.200.169:36769 in memory (size: 17.1 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 76
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1990
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1903
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1981
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 79
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2067
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2198
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1904
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1987
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 138.96.200.169:36769 in memory (size: 3.7 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2172
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 71
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 365.9 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 138.96.200.169:36769 in memory (size: 28.3 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2359
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2093
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 75
17/12/18 18:27:57 INFO ContextCleaner: Cleaned shuffle 11
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2275
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 138.96.200.169:36769 in memory (size: 17.1 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2094
17/12/18 18:27:57 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 72
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2361
17/12/18 18:27:57 INFO DAGScheduler: Got job 75 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 87 (aggregate at RegressionMetrics.scala:57)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[394] at map at RegressionMetrics.scala:55), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 87,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 87,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 394,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 394,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[394] at map at RegressionMetrics.scala:55,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 393}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 393,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[393] at map at LinearRegression.scala:632,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 392}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 392,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[392] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 391}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 391,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[391] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 390}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 390,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[390] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 389}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 389,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[389] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1905
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2250
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2223
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1983
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1982
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2354
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 138.96.200.169:36769 in memory (size: 17.1 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 23.7 KB, free 363.9 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 82
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 11.0 KB, free 363.9 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 138.96.200.169:36769 (size: 11.0 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2068
17/12/18 18:27:57 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[394] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 138.96.200.169:36769 in memory (size: 17.1 KB, free: 366.0 MB)
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 87.0 (TID 94)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2120
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 84
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 138.96.200.169:36769 in memory (size: 8.3 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2171
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1988
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2356
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2119
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2360
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1991
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1989
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 73
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1992
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2358
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2302
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2327
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 78
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 81
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1984
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2249
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2197
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2041
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2355
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2276
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 138.96.200.169:36769 in memory (size: 16.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1980
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2042
17/12/18 18:27:57 INFO BlockManager: Removing RDD 15
17/12/18 18:27:57 INFO ContextCleaner: Cleaned RDD 15
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 138.96.200.169:36769 in memory (size: 17.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 1986
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 138.96.200.169:36769 in memory (size: 15.0 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 138.96.200.169:36769 in memory (size: 28.3 KB, free: 366.2 MB)
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2353
17/12/18 18:27:57 INFO ContextCleaner: Cleaned accumulator 2328
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 87.0 (TID 94). 2300 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 94) in 23 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 87 (aggregate at RegressionMetrics.scala:57) finished in 0.024 s
17/12/18 18:27:57 INFO DAGScheduler: Job 75 finished: aggregate at RegressionMetrics.scala:57, took 0.026350 s
17/12/18 18:27:57 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/12/18 18:27:57 INFO DAGScheduler: Got job 76 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 88 (sum at RegressionMetrics.scala:71)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[395] at map at RegressionMetrics.scala:69), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 88,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 88,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 395,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 395,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[395] at map at RegressionMetrics.scala:69,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 393}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 393,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[393] at map at LinearRegression.scala:632,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 392}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 392,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[392] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 391}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 391,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[391] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 390}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 390,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[390] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 389}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 389,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[389] at rdd at LinearRegression.scala:631,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 23.3 KB, free 364.6 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 10.9 KB, free 364.6 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 138.96.200.169:36769 (size: 10.9 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[395] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 88.0 (TID 95)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 88.0 (TID 95). 1817 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 95) in 18 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 88 (sum at RegressionMetrics.scala:71) finished in 0.018 s
17/12/18 18:27:57 INFO DAGScheduler: Job 76 finished: sum at RegressionMetrics.scala:71, took 0.021167 s
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 8.766776 ms
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 308.6 KB, free 364.3 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 28.3 KB, free 364.3 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 97 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO SparkContext: Starting job: count at LinearRegression.scala:696
17/12/18 18:27:57 INFO DAGScheduler: Registering RDD 398 (count at LinearRegression.scala:696)
17/12/18 18:27:57 INFO DAGScheduler: Got job 77 (count at LinearRegression.scala:696) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 90 (count at LinearRegression.scala:696)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
17/12/18 18:27:57 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[398] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 89,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ShuffleMapStage 89,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 398,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ShuffleMapStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 398,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[398] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 397}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 397,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[397] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 396}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 396,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[396] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 19.2 KB, free 364.2 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 9.1 KB, free 364.2 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 138.96.200.169:36769 (size: 9.1 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[398] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 5316 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 89.0 (TID 96)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 89.0 (TID 96). 2400 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 96) in 14 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ShuffleMapStage 89 (count at LinearRegression.scala:696) finished in 0.014 s
17/12/18 18:27:57 INFO DAGScheduler: looking for newly runnable stages
17/12/18 18:27:57 INFO DAGScheduler: running: Set()
17/12/18 18:27:57 INFO DAGScheduler: waiting: Set(ResultStage 90)
17/12/18 18:27:57 INFO DAGScheduler: failed: Set()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[401] at count at LinearRegression.scala:696), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 90,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 90,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 401,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 401,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[401] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 400}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 400,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[400] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 399}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 399,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: ShuffledRowRDD[399] at count at LinearRegression.scala:696,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: shuffle, rddid: 398}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 7.0 KB, free 364.2 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.2 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 138.96.200.169:36769 (size: 3.7 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[401] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 97, localhost, executor driver, partition 0, ANY, 4726 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 90.0 (TID 97)
17/12/18 18:27:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/18 18:27:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 90.0 (TID 97). 1581 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 97) in 3 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 90 (count at LinearRegression.scala:696) finished in 0.003 s
17/12/18 18:27:57 INFO DAGScheduler: Job 77 finished: count at LinearRegression.scala:696, took 0.023313 s
17/12/18 18:27:57 INFO Instrumentation: LinearRegression-linReg_be181b167431-1276752040-14: training finished
17/12/18 18:27:57 INFO Instrumentation: TrainValidationSplit-tvs_1452607393ec-743752855-1: training finished
17/12/18 18:27:57 INFO FileSourceStrategy: Pruning directories with: 
17/12/18 18:27:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/18 18:27:57 INFO FileSourceStrategy: Output Data Schema: struct<label: double, features: vector>
17/12/18 18:27:57 INFO FileSourceScanExec: Pushed Filters: 
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 5.093616 ms
17/12/18 18:27:57 INFO CodeGenerator: Code generated in 13.306332 ms
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 308.6 KB, free 363.9 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 28.3 KB, free 363.9 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 138.96.200.169:36769 (size: 28.3 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 100 from broadcast at LibSVMRelation.scala:153
17/12/18 18:27:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/18 18:27:57 INFO SparkContext: Starting job: show at ModelSelectionViaTrainValidationSplitExample.scala:76
17/12/18 18:27:57 INFO DAGScheduler: Got job 78 (show at ModelSelectionViaTrainValidationSplitExample.scala:76) with 1 output partitions
17/12/18 18:27:57 INFO DAGScheduler: Final stage: ResultStage 91 (show at ModelSelectionViaTrainValidationSplitExample.scala:76)
17/12/18 18:27:57 INFO DAGScheduler: Parents of final stage: List()
17/12/18 18:27:57 INFO DAGScheduler: Missing parents: List()
17/12/18 18:27:57 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[404] at show at ModelSelectionViaTrainValidationSplitExample.scala:76), which has no missing parents
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || {
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   id: 91,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   name: ResultStage 91,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   final_rdd_id: 404,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   stage type: ResultStage,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   rdds: [
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 404,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[404] at show at ModelSelectionViaTrainValidationSplitExample.scala:76,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 403}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 403,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: MapPartitionsRDD[403] at show at ModelSelectionViaTrainValidationSplitExample.scala:76,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||          {type: narrow, rddid: 402}
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     },
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     {id: 402,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      name: FileScanRDD[402] at show at ModelSelectionViaTrainValidationSplitExample.scala:76,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      storageLevel: StorageLevel(1 replicas),
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      partitions_number: 1,
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      deps: [ 
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||      ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||     }
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO ||   ]
17/12/18 18:27:57 WARN DAGScheduler: || DAGINFO || }
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 26.7 KB, free 363.9 MB)
17/12/18 18:27:57 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 11.9 KB, free 363.9 MB)
17/12/18 18:27:57 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 138.96.200.169:36769 (size: 11.9 KB, free: 366.1 MB)
17/12/18 18:27:57 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1067
17/12/18 18:27:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[404] at show at ModelSelectionViaTrainValidationSplitExample.scala:76) (first 15 tasks are for partitions Vector(0))
17/12/18 18:27:57 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
17/12/18 18:27:57 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5327 bytes)
17/12/18 18:27:57 INFO Executor: Running task 0.0 in stage 91.0 (TID 98)
17/12/18 18:27:57 INFO FileScanRDD: Reading File path: file:///local/workspaces/kderment/repos/spark/data/mllib/sample_linear_regression_data.txt, range: 0-119069, partition values: [empty row]
17/12/18 18:27:57 INFO Executor: Finished task 0.0 in stage 91.0 (TID 98). 4117 bytes result sent to driver
17/12/18 18:27:57 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 98) in 13 ms on localhost (executor driver) (1/1)
17/12/18 18:27:57 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
17/12/18 18:27:57 INFO DAGScheduler: ResultStage 91 (show at ModelSelectionViaTrainValidationSplitExample.scala:76) finished in 0.014 s
17/12/18 18:27:57 INFO DAGScheduler: Job 78 finished: show at ModelSelectionViaTrainValidationSplitExample.scala:76, took 0.016989 s
17/12/18 18:27:57 INFO AbstractConnector: Stopped Spark@58f0ef64{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/12/18 18:27:57 INFO SparkUI: Stopped Spark web UI at http://138.96.200.169:4040
17/12/18 18:27:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/18 18:27:57 INFO MemoryStore: MemoryStore cleared
17/12/18 18:27:57 INFO BlockManager: BlockManager stopped
17/12/18 18:27:57 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/18 18:27:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/18 18:27:57 INFO SparkContext: Successfully stopped SparkContext
17/12/18 18:27:57 INFO ShutdownHookManager: Shutdown hook called
17/12/18 18:27:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-ef0a2822-99c8-4a90-b90e-6801fa246193
